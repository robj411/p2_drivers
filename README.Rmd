---
title: "DAEDALUS for CEPI's 100-day mission: code and model description"
#date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  bookdown::github_document2:
    # pandoc_args: --webtex
    toc: true
    toc_depth: 5
    toc_float: true
    number_sections: true
  bookdown::pdf_document2: 
    toc: false
    keep_tex: yes
    citation_package: natbib
    extra_dependencies: ["float"]
    # extra_dependencies: ["flafter"]
    pandoc_args:
      --filter=pandoc-xnos
    number_sections: true
    fig_caption: yes
    includes:
      in_header: "preamble.tex"
  bookdown::word_document2: 
    toc_depth: 5
    toc_float: true
    number_sections: true
    editor_options: 
      chunk_output_type: inline
bibliography: 
  - "DAEDALUS.bib"
always_allow_html: true
---

# Figures (temporary) {.unlisted .unnumbered}


```{r setup, include=FALSE}
library(ggplot2)  
library(knitr)     
library(tidyr)
library(dplyr)
library(stringi)
library(gplots)
library(RColorBrewer)
library(data.table)
library(splines)
library(bookdown)
library(pander)
library(haven)
library(viridis)
library(hrbrthemes)
library(MASS)
library(kableExtra)
library(wbstats)
library("cowplot")
library(latex2exp)


panderOptions('round',2)
panderOptions('table.split.table', Inf)

knitr::opts_chunk$set(comment=NA, prompt=FALSE, cache=FALSE, echo=F, results='asis')

format_to_print <- function(x,z=-1){
  formatC(round(x,z), format="f", digits=as.numeric(z>0), big.mark=",")
}

decimalplaces <- function(x) {
    if ((x %% 1) != 0) {
        nchar(strsplit(sub('0+$', '', as.character(format(x,scientific = F))), ".", fixed=TRUE)[[1]][[2]])
    } else {
        return(0)
    }
}

format_to_print2 <- function(x,z=2){
    v <- signif(x,z)
    sapply(v, function(i)  formatC(i, format="f", digits=decimalplaces(i), big.mark=","))
}

```


```{r dom,fig.cap='All results.',echo=F,warning=F,message=F, out.width="50%"}
knitr::include_graphics(path = "cepi_results/dominance.png")
```

```{r fig1bpsv,fig.cap='BPSV results.',echo=F,warning=F,message=F, out.width="50%"}
knitr::include_graphics(path = "cepi_results/fig1bpsv.png")
```

```{r fig2rnd,fig.cap='R&D results.',echo=F,warning=F,message=F, out.width="50%"}
knitr::include_graphics(path = "cepi_results/fig2rnd.png")
```

```{r fig3capres,fig.cap='Capacity reservation results.',echo=F,warning=F,message=F, out.width="50%"}
knitr::include_graphics(path = "cepi_results/fig3capres.png")
```

```{r fig4comb,fig.cap='Combinations results.',echo=F,warning=F,message=F, out.width="50%"}
knitr::include_graphics(path = "cepi_results/fig4comb.png")
```

```{r fig5eq,fig.cap='Equity results.',echo=F,warning=F,message=F, out.width="50%"}
knitr::include_graphics(path = "cepi_results/fig5eq.png")
```

```{r cumulativevax,fig.cap="Cumulative doses given weighted by population (where the number comes from supply, and BPSV counts for half a dose).",message=F,echo=F,warning=F}
tab <- readxl::read_xlsx('data/20250422 pandemic delivery scenarios - for ICL.xlsx')
# tab <- readxl::read_xlsx('../data/20250328 pandemic delivery scenarios - for ICL.xlsx')
nScen = (ncol(tab)-2)/6
scenario_levels <- 1:nScen
scenario_names <- colnames(tab)[!grepl('^\\.',colnames(tab))]
scen_to_keep <- 1+c(0,1,4,5,8,9,12)
tab[1,c(is.na(tab[1,]))] = ''

df_list <- list()
for(scen in 1:nScen){
  for(il in 1:3){
    start_index <- (scen-1)*6 + 1 + 2
    # print(any(tab[-c(1,2),start_index]>0 & tab[-c(1,2),start_index + 3]>0))
    get_index <- start_index - 1 + il
    ilevel <- gsub('s','',tab[2,get_index])
    scenario <- colnames(tab)[start_index]
    for(i in c(0,3)){
      vaccine <- tab[1,start_index+i][[1]]
      vindex <- get_index + i
      vals <- as.numeric(tab[-c(1:2),vindex][[1]])
      df_list[[length(df_list)+1]] <- data.frame(Day=1:length(vals), Percent=cumsum(as.numeric(vals))*100, Vaccine=vaccine,Scenario=scenario, Income=ilevel)
    }
  }
}
for(scen in 2:nScen){
  for(scen2 in 1:(scen-1)){
    difference = 0
    for(il in 1:3){
      scen1index = (scen-1)*6 + (il-1)*2 + 1
      scen2index = (scen2-1)*6 + (il-1)*2 + 1
      comp1 = df_list[[scen1index]]$Percent
      comp2 = df_list[[scen1index+1]]$Percent
      old1 = df_list[[scen2index]]$Percent
      old2 = df_list[[scen2index+1]]$Percent
      difference = difference + sum(abs(comp1-old1)+abs(comp2-old2))
    }
    # if(difference<1e-10)  print(c(scen2, scen))
  }
}



# plotscens <- do.call(rbind,df_list)
# plotscens$Percent[plotscens$Percent>80] <- 80
# plotscens$Percent[plotscens$Percent>25&plotscens$Vaccine=='BPSV'] <- 25
# ggplot(subset(plotscens,Scenario%in%scenario_names[1:4])) + 
#   geom_line(aes(x=Day,y=Percent,colour=Scenario),linewidth=2,alpha=.5) +
#   facet_grid(Vaccine~factor(Income,levels=c('LLMIC','UMIC','HIC')),scales='free_y') + 
#   theme_bw(base_size=15) + labs(colour='') +
#   theme(legend.position = 'top')


popsizes <- c(718255072+3398187527, 2503136362, 1240629858)
popsizes = popsizes/sum(popsizes)
tvaxlist <- list()
colourlists <- list(bpsv = 1+c(1,2,3,13:15,28,29), rnd = 1+c(4,5,16:19), capres = 1+c(6:9,20:27),
                    del = 1+c(10:11), eq = 1+c(0,12))

for(scen in 1:nScen){
  tvax = 0
  for(il in 1:3){
    scen1index = (scen-1)*6 + (il-1)*2 + 1
    scen2index = scen1index + 1
    comp1 = df_list[[scen1index]]$Percent
    old1 = df_list[[scen2index]]$Percent
    tvax = tvax + rev(popsizes)[il]*(0.5*comp1 + old1)
    # print(c(scen,scen1index,scen2index))
  }
  tvaxlist[[scen]] = data.frame(Day=1:length(tvax),Scenario=scenario_names[scen],Percent=tvax,
                                col=names(colourlists)[sapply(colourlists,function(x)scen%in%x)])
}

plotscens <- do.call(rbind,tvaxlist)
cscheme = 'plasma'
ggplot(plotscens) + 
  geom_line(aes(x=Day,y=Percent,colour=col,group=Scenario),linewidth=2,alpha=.75,show.legend=F) +
  geom_line(data=subset(plotscens,Scenario=='S00/BAU'),aes(x=Day,y=Percent,colour=col,group=Scenario),linewidth=2,show.legend=F) +
  theme_bw(base_size=15) + labs(colour='') +
  scale_colour_viridis_d(option = cscheme) +
  theme(legend.position = 'top')

```

```{r t50vscoverage,fig.cap="Time taken to get to 50% coverage vs final coverage (where coverage comes from supply, and BPSV counts for half a dose).",message=F,echo=F,warning=F}

midpoint <- setDT(do.call(rbind,lapply(tvaxlist,function(x)x[c(which.min(abs(x$Percent-50)),nrow(x)),])))
midpoint[,t50:=min(Day),by=Scenario]
midpoint[,coverage:=max(Percent),by=Scenario]
ggplot(unique(midpoint[,.(Scenario,t50,coverage,col)])) + 
  ggrepel::geom_label_repel(aes(x=t50,y=coverage,label=Scenario,fill=col,
                                color = after_scale(prismatic::best_contrast(fill))),
                            force=.001,vjust = 0,hjust = 0,show.legend = F) +
  # geom_point(aes(x=t50,y=coverage,colour=col,group=Scenario),show.legend=F,size=3) +
  theme_bw(base_size=15) + labs(colour='') +
  scale_fill_viridis_d(option = cscheme) +
  theme(legend.position = 'top') +
  labs(x='Time to 50% coverage, days',y='Final coverage, %')
```



# Methods {.unlisted .unnumbered}


This document describes the DAEDALUS model that is used in the CEPI application. The DAEDALUS model simulates a single epidemic in a single country. Details of how the DAEDALUS model is used as a part of the methodology of the CEPI application is presented in a separate report, which also details the scenarios which are expressed as vaccination rates and are inputs to the DAEDALUS model.


```{r internetfile,echo=F,warning=F,message=F}

internet <- read.csv('data/API_IT.NET.USER.ZS_DS2_en_csv_v2_5455054.csv',header = F) ## more recent
internet <- internet[-c(1:3),-c(3:63,65:nrow(internet))]
colnames(internet) <- c('country','Country.Code','internet')

# dataset <- read.csv('data/internetdata.csv',stringsAs=F) ## 2015/2016
# internetdata <- subset(dataset,Indicator=='Households w/ Internet access, %'&Subindicator.Type=='% households')
# internetdata$internet <- internetdata$X2016
# icols <- which(grepl('X',colnames(internetdata)))
# for(i in rev(icols)) internetdata$internet[is.na(internetdata$internet)] <- internetdata[[i]][is.na(internetdata$internet)]
# internetdata <- internetdata[,colnames(internetdata)%in%c('Country.ISO3','Country.Name','internet')]
# colnames(internetdata) <- c('Country.Code','country','internet')

incomelevels <- read.csv('data/Metadata_Country_API_IT.NET.USER.ZS_DS2_en_csv_v2_5455054.csv')
colnames(incomelevels)[1] <- 'Country.Code'

incomeint <- left_join(internet,incomelevels,by='Country.Code')
internetplot <- ggplot(subset(incomeint,!is.na(IncomeGroup)&IncomeGroup!='')) +  geom_histogram(aes(x=internet),colour='navyblue',fill='grey') +
  facet_wrap(~IncomeGroup) +
  theme_bw(base_size = 15) +
  labs(x='Internet coverage, % (I)',y='')


hic <- fitdistr(subset(incomeint,!is.na(internet)&IncomeGroup=='High income')$internet/100,"beta",start=list(shape1=1,shape2=1))
mic <- fitdistr(subset(incomeint,!is.na(internet)&IncomeGroup%in%c('Upper middle income'))$internet/100,"beta",start=list(shape1=1,shape2=1))
llmic <- fitdistr(subset(incomeint,!is.na(internet)&IncomeGroup%in%c('Low income','Lower middle income'))$internet/100,"beta",start=list(shape1=1,shape2=1))


strategies <- c('No Closures','School Closures','Economic Closures','Elimination')
newstrategies <- c('NC','RC1','RC2','RC3')
income_levels <- c('LLMIC','UMIC','HIC')
vaccination_levels <- c(365,100)
bpsv_levels <- c(0,1)

```


# Simulation rules

- The country is instantiated with two random variables: the response time, and the pathogen importation time
- The response time is the day at which the country reports having seen X hospital cases, where X is a random number between 1 and 20
- The importation time is a random number between 0 and 20 days. An importation time of 0 days would be equivalent to the spillover event.
- The epidemic simulation starts at the response or the importation time (the one that is smaller)
- At the importation time, five people are moved from compartment S to compartment E
- At the response time, testing begins and working from home begins 
- If closure policies (RC1, RC2, or RC3) are being implemented, the rules in Tables \@ref(tab:rulesreactive) or \@ref(tab:ruleselimination) are followed
<!-- ; BPSV administration begins (for investment scenarios assuming a BPSV), and we assume an uptake of 80%  -->
<!-- - The SARS-X--specific vaccine (SSV) is rolled out starting at least 107 days after the response time, depending on the investment scenario being simulated -->
<!-- - All people aged 15 and over (including those previously infected) are eligible for vaccination. We assume an uptake of 80%. -->
<!-- - The administration rate (% of population vaccinated per week) depends on investment scenario assumptions -->
- Vaccination is a model input whose details depend on the scenario. The model allows for two vaccines to be administered flexibly, in that the first is not a prerequisite for the second. In the CEPI application, the first vaccine is a broadly protective sarbecovirus vaccine (BPSV) and the second is a strain-specific vaccine (SSV).
- Closures, working from home and testing end when vaccine rollout completes (or if other stopping criteria are met, see Tables \@ref(tab:rulesreactive) and \@ref(tab:ruleselimination))
- When vaccine rollout is complete, the doubling time is more than 30 days and there are fewer than 1,000 people in hospital, the simulation ends.


# Socio-economic costs


We assign monetary values to years of life lost (YLL) and to years of education in order to add health and education costs of sector-closure policies to the costs of economic closures. We define the total socio-economic loss (TSL) of an epidemic as the sum of the three types of loss:

\begin{equation}
\text{TSL} = K_1\text{VLY} + K_2 + K_3\text{VSY},
\label{eq:swf}
\end{equation}

where $K_1$ is the number of life years lost and VLY the value of a life year; $K_2$ is the sum of lost GDP over the period due to reduced economic activity of sectors; and $K_3$ is the number of school years lost and VSY the value of one school year.

## Lost economic activity

We measure the cost of economic closures in terms of lost gross value added (GVA): the GDP generated by an economic configuration is the maximum GVA (denoted $y_j$ for each sector $j$) multiplied by the respective sector openings, summed over the period ($\tau$ days). The maximum possible GDP (which is with no closures) is 

$$Y_0=\frac{\tau}{365}\sum_{j=1}^{m_S}y_j$$

for $m_S$ sectors, and we use pre-pandemic GVA to define the maximum possible values.

All economic sectors contribute GVA according to the level they are open for production, except for the education sector which contributes its maximum possible GVA, $y_{\text{ed}}$. $x_{j}(t)$ is the proportion of the workforce contributing to economic production in sector $j$ out of the total workforce $N_j$ on day $t$. The workforce can be additionally depleted due to self isolation, sickness, hospitalisation and death, leaving a smaller fraction ($`\hat{x}_{j}(t)`$) to contribute to production.


``` math
\hat{x}_{j}(t)=x_{j}(t)\left(1 - \left(p_j^{23}(t)  + (1-q_j)p_j^{22}(t)\right)/N_j\right)
```

where $q_j$ is the fraction of the sector working from home. $p_j^{23}(t)$ represents worker sickness and death:

$$p_j^{23}(t)=\sum_{v=0}^{m_V}\left(\left(1-p^H_{j,v}\right)p^1p^{19}I_{j,v}^{s}+p^H_{j,v}p^1I_{j,v}^{s}+H_{j,v}+D_{j,v}\right),$$ 

with $m_V=2$ vaccines and $p_j^{22}(t)$ represents lost output from asymptomatic self-isolating workers:

$$p_j^{22}(t)=p^2(t)p^{18}I_{j}^{a}.$$ 

$p^{18}$ is the number of days spent in self isolation per day of infectiousness (e.g. suppose the average infectious period is four days and mandatory self-isolation time is ten days, then $p^{19}=2.5$ and $p^{18}=p^{19}T^{I^s}/T^{I^a:R}$, where $T^{I^s}$ and $T^{I^a:R}$ are expected infectious periods for symptomatic and asymptomatic, respectively). $p^1$ is compliance with the requirement to self isolate and $p^2(t)$ is the fraction of cases identified. Other notations are vaccine status $v$, infectious and asymptomatic $I_{j,v}^{a}$, infectious and symptomatic $I_{j,v}^{s}$, hospitalised $H$, deceased $D$, and probability to be hospitalised $p^H$. 

Then the total GDP is

```math
Y =  \frac{1 }{365} \sum_{j\neq\text{ed}}^{m_S}y_j\int_{t=0}^{\tau}\hat{x}_{j}(t)dt + \frac{\tau }{365}{y_\text{ed}},
```

and the GDP loss compared to the maximum is 

$$K_2=Y_0-Y.$$






## Lost lives

To value lives lost, we make use of the expected remaining life years per age group estimated by the Global Burden of Disease Network [@GlobalBurdenofDiseaseCollaborativeNetwork2021]. These are used to estimate the expected number of years of life lost per death, and to estimate the value of a life year. We map the remaining life expectancy $\tilde{l}_a$ for the GBD age groups $a$ to $l_g$ for the (different) age groups $g$ of our model as a population-weighted average, taking into account the size of each age group, $`\tilde{N}_a`$:

```math
l_g^{\text{(life)}} = \frac{\sum_{a\in g}N_a\tilde{l}_a}{\sum_{a\in g}\tilde{N}_a}; 
```

To estimate the expected number of life years lost per SARS-X death, we take into account the probability to die given infection, $P(D|I,a)$:

```math
l_g^{\text{(death)}} = \frac{\sum_{a\in g}N_a\tilde{l}_aP(D|I,a)}{\sum_{a\in g}N_aP(D|I,a)}; 
```

The total number of years lost given $D_g$ deaths due to COVID-19 for each age group is 
```math
K_1=\sum_gD_gl_g^{\text{(death)}}.
```

The value of a statistical life (VSL) reflects individuals' willingness to trade wealth for reductions in risk of mortality. We rely on the intrinsic rather than instrumental interpretation of the valuation of life [@Cutler2020], and we use an existing estimate of the VSL to estimate the value of a life year (VLY). We interpret the VSL as a population-weighted average [@Ananthapavan2021; @Robinson2021], where each age group has a VSL defined by the number of expected life years remaining, and where each year has the same value: 

\begin{equation}
\text{VSL}=\frac{\sum_gN_gl_g^{\text{(life)}}}{\sum_gN_g}\text{VLY}.
\end{equation}

Following @TheGlobalFund2022, "In this way, we made a choice to value deaths proportionally to the remaining life expectancy associated with the counterfactual of that death (how long they would live if they had not died)".

We estimate a country's VSL using the VSL of the USA, adjusting for the difference in income. We also adjust for the elasticity of willingness to pay for reductions in mortality risk relative to income. The income elasticity is likely larger in lower-income countries than in higher-income countries because the opportunity cost of spending on basic necessities becomes large if incomes are at or below subsistence levels [@Hammitt2020].


We estimate VSL as a function of GDP, relative to values for the USA:

```math
\text{VSL}=\text{VSL}_{\text{USA}}\left(r_p\frac{Y_0}{\text{GDP}_{\text{USA}}}\right)^{r_e}.
```

Here, $`\text{VSL}_{\text{USA}}`$ is a 2019 estimate of VSL for the USA (10.9 million \$) and $`\text{GDP}_{\text{USA}}`$ is its GDP. We choose randomly between two alternative methods, OECD/IHME/World Bank and Viscusi & Masterman, to map from USA's VSL to the VSL of our country, as discussed in @Robinson2021. We implement the methods using approximations to the presentations therein, which we summarise in see Table \@ref(tab:ruleselimination).  

Parameter $r_p$ is a conversion rate from GDP based on market exchange rates (MER) to GDP based on purchasing power parity (PPP). We specify that the conversion is 1, i.e. equivalence and effective valuation at MER, for the Viscusi & Masterman method, and an income-level--specific random conversion variable sampled from World Bank Data for the OECD/IHME/World Bank method. 

Parameter $r_e$ is the income elasticity. For an HIC we set it to 0.8, and otherwise we draw it from a uniform distribution between 0.9 and 1.2 with the OECD/IHME/World Bank method. For the Viscusi & Masterman method, we set it to 1 if the GDP per capita (GDPpc) is less than $8,809, and sample from a uniform distribution between 0.85 and 1 otherwise. We use this approach in order to represent our uncertainty about the appropriate method to calculate the VSL for one country using the VSL from another.

| Method | Probability | $r_p$ | $r_e$ (LLMIC) | $r_e$ (UMIC, GDPpc < \$8,809) | $r_e$ (UMIC, GDPpc > \$8,809) | $r_e$ (HIC) | 
|:----- |:----- |:----- |:----- |:----- |:----- |:----- |
| OECD/IHME/World Bank | 0.5 | Sampled from WB data | Uniform(0.9, 1.2) | Uniform(0.9, 1.2) | Uniform(0.9, 1.2) | 0.8 |
| Viscusi/Masterman | 0.5 | 1 | 1 | 1 | Uniform(0.85, 1) | Uniform(0.85, 1) |

Table: (\#tab:vslrules) values for elasticities, adapted from @Robinson2021, Table 2 (page 25)


We note that in the methods presented in Table \@ref(tab:vslrules) there is a relationship between exchange rate and elasticity, in that the flatter elasticities of Viscusi/Masterman are matched with GDP based on MER, whereas the more graduated elasticities of the OECD/IHME/World Bank method are matched with GDP based on PPP. This might be because these choices enact inverse transformations of low VSL values for GDP (Figure \@ref(fig:pppelasticity)). 


```{r pppelasticity,fig.cap='Exposition of different methods to estimate VSL from GDP per capita relative to the USA. On the y axis is VSL expressed as a percentage of GDP per capita. The grey line indicates the VSL of the USA. We compare GDP per capita expressed using market exchange rates (MER) vs. purchasing power parity (PPP), and an income elasticity of 1 vs. 1.5. Data source: World Bank.',echo=F,warning=F,message=F}

gdpdata <- setDT(wb_data("NY.GDP.PCAP.CD",country = "countries_only", start_date = 2018, end_date = 2024))
gnipppdata <- setDT(wb_data("NY.GDP.PCAP.PP.CD",country = "countries_only", start_date = 2018, end_date = 2024))
joineddata <- left_join(gdpdata[,.(iso3c,country,date,NY.GDP.PCAP.CD)],gnipppdata[,.(iso3c,country,date,NY.GDP.PCAP.PP.CD)],by=c('iso3c','country','date'))
joineddata <- subset(joineddata,!is.na(NY.GDP.PCAP.PP.CD)&!is.na(NY.GDP.PCAP.CD))
joineddata[,mostrecent:=max(date),by=country]
joineddata <- subset(joineddata,date==mostrecent)
joineddata[,gdp_to_gnippp:=NY.GDP.PCAP.PP.CD/NY.GDP.PCAP.CD]
joineddata <- left_join(joineddata,setDT(incomelevels)[,.(Country.Code,IncomeGroup)],by=c('iso3c'="Country.Code"))


joineddata[,gnippp:=gdp_to_gnippp*NY.GDP.PCAP.CD]
usagdppc <- with(subset(joineddata,iso3c=='USA'),NY.GDP.PCAP.CD)
yint <- with(subset(joineddata,iso3c=='USA'),(10^6*10*(NY.GDP.PCAP.CD/usagdppc)^1.)/NY.GDP.PCAP.CD)
joineddata[,minvsl:=20*NY.GDP.PCAP.CD]
joineddata[,basicvsl:=max(minvsl,10^6*10*(NY.GDP.PCAP.CD/usagdppc)^1.),by=iso3c]
joineddata[,vsle:=max(minvsl,10^6*10*(NY.GDP.PCAP.CD/usagdppc)^1.5),by=iso3c]
joineddata[,vslpppe:=max(minvsl,10^6*10*(gnippp/usagdppc)^1.5),by=iso3c]
joineddata[,vslppp:=max(minvsl,10^6*10*(gnippp/usagdppc)^1.),by=iso3c]

p11 <- ggplot(joineddata,aes(x=NY.GDP.PCAP.CD,y=basicvsl/NY.GDP.PCAP.CD)) + 
  geom_hline(yintercept=yint,linewidth=2,colour='grey') +
  # annotate('rect',ymin=10^(1.5),ymax=10^(2),xmin=-Inf,xmax=Inf,fill='goldenrod',alpha=.25) +
  geom_point(aes(colour=IncomeGroup),show.legend=F) + theme_bw(base_size = 13) +
  labs(x='GDP pc',y='VSL/GDPpc',title=TeX('MER, $r_e$=1'),colour='') 
p12 <- ggplot(joineddata,aes(x=(NY.GDP.PCAP.CD),y=vslppp/NY.GDP.PCAP.CD)) + 
  geom_hline(yintercept=yint,linewidth=2,colour='grey') +
  # annotate('rect',ymin=10^(1.5),ymax=10^(2),xmin=-Inf,xmax=Inf,fill='goldenrod',alpha=.25) +
  geom_point(aes(colour=IncomeGroup),show.legend=F) + theme_bw(base_size = 13) +
  labs(x='GDP pc',y='VSL/GDPpc',title=TeX('PPP, $r_e$=1'),colour='') 
p21 <- ggplot(joineddata,aes(x=(NY.GDP.PCAP.CD),y=vsle/NY.GDP.PCAP.CD)) + 
  geom_hline(yintercept=yint,linewidth=2,colour='grey') +
  # annotate('rect',ymin=10^(1.5),ymax=10^(2),xmin=-Inf,xmax=Inf,fill='goldenrod',alpha=.25) +
  geom_point(aes(colour=IncomeGroup),show.legend=F) + theme_bw(base_size = 13) +
  labs(x='GDP pc',y='VSL/GDPpc',title=TeX('MER, $r_e$=1.5'),colour='') 
p22 <- ggplot(joineddata,aes(x=(NY.GDP.PCAP.CD),y=vslpppe/NY.GDP.PCAP.CD)) + 
  geom_hline(yintercept=yint,linewidth=2,colour='grey') +
  # annotate('rect',ymin=10^(1.5),ymax=10^(2),xmin=-Inf,xmax=Inf,fill='goldenrod',alpha=.25) +
  geom_point(aes(colour=IncomeGroup),show.legend=F) + theme_bw(base_size = 13) +
  labs(x='GDP pc',y='VSL/GDPpc',title=TeX('PPP, $r_e$=1.5'),colour='') 


plot_grid(p11,p21,p12,p22,ncol = 2, nrow = 2)
```


## Lost education


The loss due to school closure is

<!-- $$K3 =  \frac{p^{14} }{365}\left( Tp^{16}N_{j_{\text{school}}}+p^{24} + (1-p^{16})p^{25} \right)\text{VSY}$$ -->
$$K_3 =  \frac{1 }{365} \int_{t=0}^{\tau}\left(p^{14}(t)N_{j_{\text{school}}} + (1-p^{14}(t))p^{25}(t)  +(1-2p^{14}(t))p^{24}(t)\right)dt,$$

where $p^{14}(t)$ is the effective amount of education lost per student at time $t$ due to school closure:
$$p^{14}(t) = (1-p^{16})(1-x_{\text{ed}}(t)),$$
$N_{j_{\text{school}}}$ is the total number of students, $p^{16}$ is relative effectiveness of remote education and $x_{\text{ed}}(t)$ is the openness of schools, $p^{25}(t)$ represents education lost due to student sickness with COVID-19:

$$p^{25}(t)=\sum_{v=0}^{m_V}\left((1-p^H_{j_{\text{school}},v})p^1p^{19}I_{j_{\text{school}},v}^{s}+p^H_{j_{\text{school}},v}p^1I_{j_{\text{school}},v}^{s}+H_{j_{\text{school}},v}\right),$$ 

$p^{18}$ is the number of days spent in self isolation per day of infectiousness (e.g. suppose the average infectious period is four days and mandatory self-isolation time is ten days, then $p^{19}=2.5$ and $p^{18}=p^{19}T^{I^s}/T^{I^a:R}$, where $T^{I^s}$ and $T^{I^a:R}$ are expected infectious periods for symptomatic and asymptomatic, respectively), and $p^{24}(t)$ represents education lost due to asymptomatic self isolation (which comes at a cost only when schools are open):

$$p^{24}(t)=p^2(t)p^{18}I_{j_{\text{school}}}^{a}.$$ 

For the value of a year of education, we use the method of [@Psacharopoulos2021a]. 

$$\text{VSY} =  p^{12}\cdot p^{13}\cdot p^{15}.$$

$p^{12}$ is the present value of lost earnings:

$$p^{12} = \frac{1}{N_{j_{\text{school}}}}\sum_{a\in j_{\text{school}}}\tilde{N}_a\left( \frac{1-(1+r)^{-(m_Y+20-a)}}{r} -  \frac{1-(1+r)^{-(20-a)}}{r}\right)$$

for discount rate $r=0.03$, number $\tilde{N}_a$ students currently age $a$, and expected number of years of work $m_Y=45$. $p^{13}$ is mean annual earnings (estimated using GDP multiplied by labour share of income [@Feenstra2015]), and $p^{15}=0.08$ is the rate of return for one year of education.

The value $p^{16}$ represents the effectiveness of remote teaching, which we sample as a standard uniform random variable. We note that no strong predictors of effectiveness of remote teaching have been identified [@Patrinos2023]. We assume that losses are linear in duration of school closure, although there is not consensus even on this [@Betthauser2023]. Important factors to include in future work might be those relating to parental circumstances including education level, engagement and socio-economic status [@Moscoviz2022]. These factors might be more pertinent to intra- rather than international modelling.







# Epi model

The epidemiological component of the DAEDALUS model is a deterministic compartmental model that consists of seven disease states (susceptible, exposed, asymptomatic infectious, symptomatic infectious, hospitalised, recovered, and deceased), in triplicate to represent vaccination states unvaccinated, vaccinated with the BPSV, and vaccinated with the SSV. The population is stratified by age (into four age groups: pre-school children, school-age children, working-age adults, and retirement-age adults). The working-age adults are further stratified into 46 groups: 45 economic sectors, plus one non-working group.

## Ordinary differential equations

\begin{align}
\frac{dS_{j,v}}{dt} & = \sum_{u=0}^{v-1}k^9S_{j,u}^{c_v} - \left( k_{j,v}^{1}(t) + \sum_{u=v+1}^{{m_V}}k_{j,v}^{10,c_u}(t) \right)S_{j,v} \\
\frac{dS_{j,u}^{c_v}}{dt} & = k_{j,u}^{10,c_v}(t)S_{j,u} -\left( k_{j,u}^{1}(t) + k^9 \right)S_{j,u}^{c_v}  \\
\frac{dE_{j,v}}{dt} & = k_{j,v}^{1}(t)\left(S_{j,v}+\sum_{u=v+1}^2S_{j,v}^{c_u}\right) - (k^2+k^4)E_{j,v} \\
\frac{dI_{j,v}^a}{dt} & = k^2E_{j,v} - k^3I_{j,v}^a \\
\frac{dI_{j,v}^s}{dt} & = k^4E_{j,v} - (k_{j,v}^{5}+k_{j,v}^{6})I_{j,v}^s \\
\frac{dR_{j,v}}{dt} & = k^3I_{j,v}^a + k_{j,v}^{5}I_{j,v}^s + k_{j}^{7}(t) H_{j,v} - \sum_{u=v+1}^{{m_V}}k_{j,v}^{10,c_u}(t)R_{j,v} + \sum_{u=0}^{v-1}k_{u,j}^{10,c_v}(t)R_{j,v-1}\\
\frac{dH_{j,v}}{dt} & = k_{j,v}^{6}I_{j,v}^s - (k_{j}^{7}(t) + k_{j}^{8}(t)) H_{j,v} \\
\frac{dD_{j,v}}{dt} & =  k_{j}^{8}(t) H_{j,v}
\end{align}




## Disease state transitions

```{tikz statetransitions, fig.cap = "Disease state transitions. $S$: susceptible. $E$: exposed. $I^{a}$: asymptomatic infectious. $I^{s}$: symptomatic infectious. $H$: hospitalised. $R$: recovered. $D$: died. $j$: stratum. $v$: vaccination status.", fig.ext = 'png',echo=F, out.width="50%"}


\usetikzlibrary{shapes}
\usetikzlibrary{fit}
\usetikzlibrary{arrows}
\usetikzlibrary{positioning,arrows.meta}
\tikzset{
     block/.style={rectangle, draw, fill=red!40, text width=6em,
                   text centered, rounded corners, minimum height=3em},
     arrow/.style={-{Stealth[]}}
}
\tikzstyle{plate} = [draw, rectangle, rounded corners, fit=#1]
\tikzstyle{wrap} = [inner sep=0pt, fit=#1]
\tikzstyle{caption} = [font=\footnotesize, node distance=0] %
\tikzstyle{plate caption} = [caption, node distance=0, inner sep=0pt,
below left=5pt and 0pt of #1.south east] %
\tikzstyle{factor caption} = [caption] %
\tikzstyle{every label} += [caption] %

\newcommand{\plate}[4][]{ %
  \node[wrap=#3,#1] (#2-wrap) {}; % draw box round #3, called #2, with parameters #1
  \node[plate caption=#2-wrap] (#2-caption) {#4}; % fit caption
  \node[plate=(#2-wrap)(#2-caption)] (#2) {}; % draw (used to have #1)
}
\tikzstyle{latent} = [circle,fill=white,draw=black,inner sep=1pt,
minimum size=15pt, font=\fontsize{10}{10}\selectfont, node distance=1]
\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1cm,y=1cm]
    \node[latent] (S) {$S_{j,v}$} ; %
    \node[latent, right=of S] (E1) {$E_{j,v}$} ; %
    \node[latent, right=of E1] (L1) {$I_{j,v}^{s}$} ; %
    \node[latent, above=of L1] (L2) {$I_{j,v}^{a}$} ; %
    \node[latent, below=of L1] (I1) {$H_{j,v}$} ; %
    \node[latent, right=of L1] (R) {$R_{j,v}$} ; %
    \node[latent, right=of I1] (D) {$D_{j,v}$} ; %
    \draw [arrow] (S) -- node [above] {$k^{1}_{j,v}(t)$} (E1);
    \draw [arrow] (E1) -- node [above] {$k^4$} (L1);
    \draw [arrow] (E1) -- node [above] {$k^2$} (L2);
    \draw [arrow] (L1) -- node [left] {$k^{6}_{j,v}$} (I1);
    \draw [arrow] (L1) -- node [above] {$k^{5}_{j,v}$} (R);
    \draw [arrow] (L2) edge[bend left=10] node [above] (T6) {$k^3$} (R);
    \draw [arrow] (I1) -- node [right] {$k^{7}_{j}(t)$} (R);
    \draw [arrow] (I1) -- node [above] {$k^{8}_{j}(t)$} (D);
   \plate[inner sep=0.25cm, yshift=0.12cm] {plate3} {(S) (L2) (D)} {$j\in\{1,...,m_J\}; v\in\{0,1,2\}$}; 
\end{tikzpicture}
```


Possible transitions between disease states are shown in Figure \@ref(fig:statetransitions). Transition rates are functions of time $t$, vaccination status $v$, and group identity $j$ (where the groups are the 45 sectors and the four age groups).

The rate of infection of susceptible individuals, $`k^{1}_{j,v}(t)`$, is defined as

\begin{equation}
k_{j,v}^{1}(t) = \eta_{v}^{E}\rho(t)\beta\sum_{h=1}^{m_J}M_{j,h}(x) I_h(t)
(\#eq:infection)
\end{equation}

with $m_J=49$ strata and 

```math
 I_h(t)=\sum_{v=0}^{m_V}\left(\epsilon (1-p^3(t))I_{h,v}^{a}(t)+(1-p^4(t))I_{h,v}^{s}(t)\right). 
```

  Here, $`\eta^{E}_{v}`$ is the relative probability to be infected given vaccine status $v$; $\rho(t)$ is the time-dependent modifier of the rate of infection, $\beta$, which captures the impact of uncosted transmission reductions; $M(x)$ is the contact matrix between groups and depends on the economic configuration $x$; $\epsilon$ is the reduction in infectiousness from asymptomatic relative to symptomatic individuals; $p^3$ and $p^4$ are the proportions of asymptomatic and symptomatic infectiousness averted, respectively, due to self isolating; and $I_{h,\cdot}^{\cdot}$ is the number of infectious asymptomatic ($I_{h,\cdot}^{a}$) and symptomatic ($I_{h,\cdot}^{s}$) people who are unvaccinated ($I_{h,v=0}^{\cdot}$), vaccinated with the BPSV ($I_{h,v=1}^{\cdot}$), or vaccinated with the specific vaccine ($I_{h,v=2}^{\cdot}$) in stratum $h$.

```math
 k^2 = \big(1-p^{I^S}\big)/T^{E:I} 
```

  is the rate to asymptomatic infectiousness, where $p^{I^S}$ is the probability to become symptomatic given infection, and $T^{E:I}$ is the expected duration of the latent period before the onset of infectiousness;

```math
 k^3 = 1/T^{I^a:R}  
```

  is the rate of recovery from asymptomatic infection;

```math
 k^4 = p^{I^S}/ T^{E:I}; 
```

  is the rate of symptom onset;

```math
k^{5}_{j,v} =  \big(1-p^H_{j,v}\big) / T_{j,v}^{I^s}
```

  is the rate of recovery from symptomatic infection, where $p^H_{j,v}$ is the probability to be hospitalised given symptomatic infection, and $T_{j,v}^{I^s} = p^H_{j,v}T^{I^s:H} + (1-p^H_{j,v})T^{I^s:R}$ is the expected time to be in compartment $I^s$: $T^{I^s:H}$ is the expected duration before hospitalisation and $T^{I^s:R}$ is the expected duration before recovery.
  
```math
p^H_{j,v}=\eta^{H}_{v}\tilde{p}^{H}_{j}
```

  is the baseline probability to be hospitalised ($`\tilde{p}^{H}_{j}`$) adjusted by the vaccine effect protecting against hospitalisation ($`\eta^{H}_{v}`$). Then

```math
k^{6}_{j,v} = p^H_{j,v}/T_{j,v}^{I^s}
```

  is the rate of hospitalisation following symptomatic infection.

```math
k^{7}_{j}(t) = (1-p^{D}_{j}(t)) / T_j^{H}(t)
```

  is the rate of recovery of hospitalised patients, where $`p^{D}_{j}(t)=\tilde{p}^{D}_{j}f_H(t)`$ is the baseline probability to die given hospitalisation, adjusted by a factor encoding the increase in fatality rate as hospital occupancy increases:
  
<!-- (1 + 0.87*max(0, occ - Hmax) / occ)*pd; -->

  
```math
f_H(t)=1 + 5\frac{\max\{0,H_{\text{tot}}(t)-H_{\text{max}}\}}{H_{\text{tot}}(t)},
```

```math
H_{\text{tot}}(t) = \sum_{v=0}^{m_V}\sum_{j=1}^{m_J} H_{j,v}(t).
```

$$T_j^{H}(t) = p_j^{D}(t)T^{H:D} + (1-p_{j}^{D}(t))T^{H:R}$$

is the expected time to be in compartment $H$: $T^{H:D}$ is the expected duration before death and $T^{H:R}$ is the expected duration before recovery. Finally,

```math
k^{8}_{j}(t) = p^{D}_{j}(t)/T_j^{H}(t)
```

  is the rate of death following hospitalisation.

## Vaccination state transitions

In our model, $v=0$ refers to unvaccinated people, $v=1$ to people who have received a full schedule of BPSV, and $v=2$ to people who have received a full schedule of the specific vaccine. How we model transitions between vaccination states is shown in Figure \@ref(fig:vaccinetransitions).

$`k^{10,c_1}_{j,v=0}(t)`$ represents the rates of BPSV vaccination of unvaccinated susceptible and recovered people, and $`k^{10,c_2}_{j,v=1}(t)`$ represents the rates of vaccinating BPSV-vaccinated susceptible and recovered people. $`k^{10,c_2}_{j,v=0}(t)`$ represents the rates of vaccinating people directly with the specific vaccine. Put more succinctly, $`k^{10,c_u}_{j,v}(t)`$ is the rate to go from vaccine state $v$ to $u$. $k^9=1/T^c$ is the rate of seroconversion to vaccine-induced immunity, and $`k^{12}_{j}(t)=k^{1}_{j,v=0}(t)`$ and $`k^{19}_{j}(t)=k^{1}_{j,v=1}(t)`$ are the rates of infection of just-vaccinated people, which returns them to the epidemiological pathway of the lower vaccination level.

```{tikz vaccinetransitions, fig.cap = "Vaccine state transitions. $S$: susceptible. $S^{c_u}, u\\in\\{1,2\\}$: recently vaccinated but has not yet seroconverted (i.e. is not protected by most recent vaccination). $R$: recovered. $j$: stratum. $v$: initial vaccination status. $u$: final vaccination status.", fig.ext = 'png',echo=F}
\usetikzlibrary{shapes}
\usetikzlibrary{fit}
\usetikzlibrary{arrows}
\usetikzlibrary{positioning,arrows.meta}
\tikzset{
     block/.style={rectangle, draw, fill=red!40, text width=6em,
                   text centered, rounded corners, minimum height=3em},
     arrow/.style={-{Stealth[]}}
}
\tikzstyle{plate} = [draw, rectangle, rounded corners, fit=#1]
\tikzstyle{wrap} = [inner sep=0pt, fit=#1]
\tikzstyle{caption} = [font=\footnotesize, node distance=0] %
\tikzstyle{plate caption} = [caption, node distance=0, inner sep=0pt,
below left=5pt and 0pt of #1.south east] %
\tikzstyle{factor caption} = [caption] %
\tikzstyle{every label} += [caption] %

\newcommand{\plate}[4][]{ %
  \node[wrap=#3,#1] (#2-wrap) {}; % draw box round #3, called #2, with parameters #1
  \node[plate caption=#2-wrap] (#2-caption) {#4}; % fit caption
  \node[plate=(#2-wrap)(#2-caption)] (#2) {}; % draw (used to have #1)
}
\tikzstyle{latent} = [circle,fill=white,draw=black,inner sep=1pt,
minimum size=20pt, font=\fontsize{10}{10}\selectfont, node distance=1]
\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1cm,y=1cm]
%\clip (-3, -10) rectangle (7, 1);
\node[latent] (S) {$S_{j,v=0}$} ; %
    \node[latent, draw=white,right=of S,xshift=1cm] (em) {$...$} ; %
    \node[latent, right=of em] (R) {$R_{j,v=0}$} ; %
    \node[latent, below=of S,yshift=-1cm] (S01) {$S_{j,v=0}^{c_1}$} ; %
    \node[latent, below=of S01] (S1) {$S_{j,v=1}$} ; %
    \node[latent, draw=white,right=of S1,xshift=1cm] (emv) {$...$} ; %
    \node[latent, right=of emv] (Rv) {$R_{j,v=1}$} ; %
    \node[latent, below=of S1,yshift=-1cm] (S12) {$S_{j,v=1}^{c_2}$} ; %
    \node[latent, left=of S12,xshift=.7cm] (S02) {$S_{j,v=0}^{c_2}$} ; %
    \node[latent, below=of S12] (S2) {$S_{j,v=2}$} ; %
    \node[latent, draw=white,right=of S2,xshift=1cm] (emv2) {$...$} ; %
    \node[latent, right=of emv2] (Rv2) {$R_{j,v=2}$} ; %
    \draw [arrow] (S) -- node [right,yshift=.5cm] {$k^{10,c_1}_{j,v=0}(t)$} (S01);
    \draw [arrow] (S) -- node [above] {} (em);
    \draw [arrow] (em) -- node [above] {} (R);
    \draw [arrow] (S01) -- node [right] {$k^{12}_{j}(t)$} (em);
    \draw [arrow] (S02) edge[bend right] node [right,yshift=.5cm,xshift=.25cm] {$k^{12}_{j}(t)$} (em);
    \draw [arrow] (S12) -- node [right] {$k^{19}_{j}(t)$} (emv);
    \draw [arrow] (S1) -- node [above] {} (emv);
    \draw [arrow] (emv) -- node [above] {} (Rv);
    % \draw [arrow] (R) edge[bend right] node [above] {$k^{13}$} (S);
    \draw [arrow] (S01) -- node [right] {$k^9$} (S1);
    % \draw [arrow] (Rv) edge[bend right=-30] node [below] {$k^{14}$} (S1);
    % \draw [arrow] (Rv2) edge[bend right=-30] node [below] {$k^{18}$} (S2);
    \draw [arrow] (S) edge[bend right] node [left] (ks02) {$k^{10,c_2}_{j,v=0}(t)$} (S02);
    \draw [arrow] (R) edge[bend left] node [right] (kr02) {$k^{10,c_2}_{j,v=0}(t)$} (Rv2);
    \draw [arrow] (R) -- node [left] {$k^{10,c_1}_{j,v=0}(t)$} (Rv);
    \draw [arrow] (S1) -- node [left] {$k^{10,c_2}_{j,v=1}(t)$} (S12);
    \draw [arrow] (S12) -- node [right] {$k^9$} (S2);
    \draw [arrow] (S02) -- node [right] {$k^9$} (S2);
    \draw [arrow] (Rv) -- node [left] {$k^{10,c_2}_{j,v=1}(t)$} (Rv2);
    \draw [arrow] (S2) -- node [above] {} (emv2);
    \draw [arrow] (emv2) -- node [above] {} (Rv2);
   \plate[inner sep=0.25cm, yshift=0.12cm] {plate3} {(S) (Rv2) (ks02) (kr02)} {$j\in\{1,...,m_J\}$}; 
\end{tikzpicture}

```

### Vaccine effects

Quantity | BPSV | SSV
|:----- |:----- |:----- |
Time to develop immunity | 21 days | 21 days 
Effectiveness against infection | 0.35 | 0.55 
Effectiveness against hospitalisation | 0.8 | 0.9 
Effect on transmission | 0 | 0 
Rate of waning | 0 | 0 

Table: (\#tab:vaccineeffects) Vaccine effects. The Time to develop immunity is the average time it takes a person to go from the Susceptible compartment to the Vaccinated equivalent compartment, such that the rate of transition is 1/21 per day. The Effectiveness against infection is one minus the relative risk of infection of a vaccinated person compared to an unvaccinated person. The Effectiveness against hospitalisation is one minus the relative risk of hospitalisation of a vaccinated person compared to an unvaccinated person. The Effect on transmission is one minus the relative infectiousness of an infectious vaccinated person compared to an infectious unvaccinated person. The Rate of waning is the rate at which the vaccine effects decay over time.


## Contact rates

The configuration $x$ and the proportion of workers working from home $q$ determine the scaling of exposure to infection between different groups for different reasons:

- Worker absence due to sector closure
- Worker absence due to working from home
- Student absence due to school closure
- Customer absence due to sector closure: impact on workers
- Customer absence due to sector closure: impact on customers

We approach this differently from [@Haw2020]. Instead of contact matrices from [@Prem2021], we use those from [@Walker2020]. Instead of work contacts from [@Beraud2015], we use those from [@Jarvis2023]. [@Haw2020] modelled closures using a combination of moving workers between sector compartments and a non-working compartment, and scaling of contacts. Here, we only use contacts to model closures, and do not move workers out of their compartments. An advantage of this is that workers within sectors retain their infection histories. 

We construct contact matrix $M(x)$ as the sum of three matrices: $M^{\text{com}}(x)$ (community contacts), $M^{\text{CW}}(x)$ (community-to-worker contacts), and  $M^{\text{WC}}(x)$ (worker-to-community contacts). We construct peacetime matrices ($x=\textbf{1}$) beginning with a "target matrix", which the three matrices should add up to, which is taken from [@Walker2020]. By sampling relevant values, we decompose the whole matrix into its component parts. To incorporate closures, each matrix is transformed independently, before they are all added together again.

Matrix $M(\textbf{1})$ is estimated using as a basis a contact matrix from [@Walker2020]. These are 16-by-16 matrices, $\tilde{M}$, for five-year age bands $a$ up to age group 75+. We map the matrix to a four-by-four matrix $\hat{M}$ corresponding to the four age groups $g$ used in the DAEDALUS model, using population sizes $\tilde{N}_a$:

```math
\hat{M}_{gg'} = \frac{\sum_{a\in g}\tilde{N}_{a}\sum_{a'\in g'}\tilde{M}_{a,a'}}{\sum_{a\in g}\tilde{N}_{a}},
```

and $\hat{N}_g$ to represent the population sizes of the DAEDALUS age groups,

```math
\hat{N}_g=\sum_{a\in g}\tilde{N}_a.
```

We get to the matrix $M(\textbf{1})$ by broadcasting the four-by-four matrix to the 49-by-49 one. Contacts from all groups $j$ to working groups $h$ depend on the age group of the group ($`g(j)`$), and the fraction of the age-population represented in group $h$, where $N_{h}$ is the number of people in group $h$:

```math
M_{j,h}(\textbf{1}) = \hat{M}_{g(j),g(h)}\frac{N_{h}}{\hat{N}_{g(h)}}
```

for $j$ and $h$ including all groups (working and non-working). Each group $j$ contains people that belong to only one age group $g$. We refer to the age group of the people in group $j$ as $g(j)$. Then $\hat{N}_{g(h)}$ is the number of people in the age group of group $h$, so $`\hat{N}_{g(h)}=N_{h}`$ for age groups 0 to 4, 5 to 19 and 65+, and $`\hat{N}_{g(h)}=\sum_{h\in\{1,...,m_S,m_S+3\}}N_{h}`$ for age group 20 to 64. 

In setting up a country, we sample values for $\tilde{M}$ (from which we get $`M(\textbf{1})`$). At the same time, we sample the proportion of contacts that come from workplaces (Figure \@ref(fig:workfrac)), and workplace-related contacts. From these, we get $M^{\text{CW}}(\textbf{1})$, constructing the matrices and normalising. 

Community-to-worker contacts (matrix $M^{\text{CW}}$) describe contacts experienced by workers from the community by sector (Figure \@ref(fig:allsector), distributed by age, Figure \@ref(fig:uksecdistage)). Note that $`M^{\text{CW}}_{j,h}(\textbf{1})=0`$ for $j>m_S$. Matrix $M^{\text{WC}}(\textbf{1})$ is the complement of matrix $M^{\text{CW}}(\textbf{1})$, computed by multiplying through by population, transposing, and dividing again by population.

With $M(\textbf{1})$, $M^{\text{CW}}(\textbf{1})$ and $M^{\text{WC}}(\textbf{1})$, we learn $M^{\text{com}}(\textbf{1})$. 

$M^{\text{com}}(\textbf{1})$ is decomposed into its constituent parts, representing intra- and inter-household interactions (home), school interactions (sch) and hospitality interactions (CC):

```math
M^{\text{com}}(\textbf{1})=M^{\text{home}} + M^{\text{sch}}(\textbf{1}) + M^{\text{CC}}(\textbf{1}) 
```

Values for $M^{\text{sch}}(\textbf{1})$ come from sampled values representing the fractions of contacts that come from school. School contacts are estimated separately in two age groups (pre-school age: 0-–4 (Figure \@ref(fig:school1frac)); school age: 5-–19 (Figure \@ref(fig:school2frac))): $M^{\text{sch}}(\textbf{1})$ has entries of zero for groups not in school, and values for 0 to 4 year olds and 5 to 19 year olds. 

<!-- Likewise, $M^{\text{tran}}(\textbf{1})$ is also sampled as a fraction of total contacts. $M_{j,h}^{\text{tran}}(\textbf{1})\geq 0$ for $j=1,...,m_S$. $M_{j,h}^{\text{tran}}(\textbf{1})=0$ for $j>m_S$. -->

Finally, $M^{\text{CC}}(\textbf{1})$ is sampled as a fraction of $M^{\text{com}}(\textbf{1})- M^{\text{sch}}(\textbf{1})$ (Figure \@ref(fig:hospfrac), distributed by age, Figure \@ref(fig:conagefrac)), which leaves $M^{\text{home}}$. Community contacts in consumption settings includes contacts made on public transport, as these contacts are small in number and are most correlated with consumption (and not work or school) [@Jarvis2023]. (This might be because contacts are counted by how many people you talk to.)

```{r workfrac,fig.cap='Fraction of contacts made at work, from [@Jarvis2023]. Extrapolated from three countries (UK, Belgium, Netherlands), whose values are all close to 40%, using time-use survey results for fraction of time spent at work (OECD, last updated December 2023, 33 countries, with values ranging from 12 to 25% (and the three reference countries have values 16 to 18%)).', echo=F,message=F,warning=F, out.width="50%"}
knitr::include_graphics(path = "README_files/figure-gfm/workfrac.png")
```

```{r allsector,fig.cap='Number of contacts made at work, from [@Jarvis2023]. Diamonds show average numbers and ranges are 50% quantile intervals. We sample values from half to double the average. Data come from UK, Netherlands and Switzerland, with occupation ISCO-88 mapped to ISCO-08 then SOC-10 then ISIC rev 4 using ONS data.', echo=F,message=F,warning=F, out.width="50%"}
knitr::include_graphics(path = "README_files/figure-gfm/allsector45.png")
```

```{r uksecdistage,fig.cap='Fraction of contacts made at work by age, from [@Jarvis2023].', echo=F,message=F,warning=F, out.width="50%"}
knitr::include_graphics(path = "README_files/figure-gfm/uksec_dist_age.png")
```

```{r school1frac,fig.cap='Fraction of contacts made at school for ages 0 to 4, from [@Jarvis2023].', echo=F,message=F,warning=F, out.width="50%"}
knitr::include_graphics(path = "README_files/figure-gfm/school1frac.png")
```

```{r school2frac,fig.cap='Fraction of contacts made at school for ages 5 to 19, from [@Jarvis2023].', echo=F,message=F,warning=F, out.width="50%"}
knitr::include_graphics(path = "README_files/figure-gfm/school2frac.png")
```

```{r hospfrac,fig.cap='Fraction of non-school and non-work contacts made in hospitality settings, by age group, from [@Jarvis2023].', echo=F,message=F,warning=F, out.width="50%"}
knitr::include_graphics(path = "README_files/figure-gfm/hospfrac.png")
```

```{r conagefrac,fig.cap='Distribution of non-school and non-work contacts made in hospitality settings by age group, from [@Jarvis2023].', echo=F,message=F,warning=F, out.width="50%"}
knitr::include_graphics(path = "README_files/figure-gfm/conagefrac.png")
```


### Community contacts

We construct $M^{\text{com}}(x)$ from its constituent parts, representing intra- and inter-household interactions (home), school interactions (sch) and hospitality interactions (CC):

```math
M^{\text{com}}(x)=M^{\text{home}} + M^{\text{sch}}(x) + M^{\text{CC}}(x).
```

School contacts under $x$ are the peacetime values scaled by the extent of closure. $x_{\text{ed}}$ is the extent to which schools are open, so that the number of contacts per person scales superlinearly with school closure. 

\begin{equation}
M_{j,j}^{\text{sch}}(x)=x_{\text{ed}}^2M_{j,j}^{\text{sch}}(\textbf{1}).
(\#eq:school)
\end{equation}



<!-- Matrix  $M^{\text{tran}}$ counts contacts between working people, representing travel. We assume that transport contacts only add to the infection risk if the sector is open and the workers travel to and from their workplace. Again, the value for configuration $x$ is the value for $\textbf{1}$ scaled accordingly: -->

<!-- \begin{equation} -->
<!-- M_{j,h}^{\text{tran}}(x) = x_{h}(1-q_j)(1-q_h)M_{j,h}^{\text{tran}}(\textbf{1}). -->
<!-- (\#eq:travel) -->
<!-- \end{equation} -->

<!-- $q_j$ is the proportion of workers from sector $j$ working from home, and $(1-q_j)(1-q_h)$ scales contacts between workers superlinearly to approximate the reduced transmission between commuting workers: there should be fewer contacts per person on average, and there should be fewer people having these contacts.  -->

<!-- Also in this equation, $x_{h}$ scales the numbers of contacts linearly with respect to sector closure. At the same time, the number of people in the compartments will be reduced by their sector closure, $x_{j}$. This, in combination with the scaled contacts, leads to superlinear scaling. -->



Matrix  $M^{\text{CC}}(x)$ gives the contacts made in the hospitality sector:

\begin{equation}
M^{\text{CC}}(x) = (p^{27})^2M^{\text{CC}}(\textbf{1})
(\#eq:hosp)
\end{equation}

The value $p^{27}$ is the workforce-weighted average extent to which the hospitality sectors are open, so that the number of contacts per person scales superlinearly according to closure:

```math
p^{27} = \frac{\sum_jx_{j}N_j}{\sum_jN_j}
```

where we sum over only the hospitality sectors.



### Community-to-worker contacts

\begin{equation}
M_{j,h}^{\text{CW}}(x) = (x_{j}(1-q_j))^2M_{j,h}^{\text{CW}}(\textbf{1}),
(\#eq:ctow)
\end{equation}

for $h\in\{1,...,m_J\}$. 

Here, there is superlinear scaling of $M^{\text{CW}}_{j,h}(\textbf{1})$ with respect to working from home and with respect to sector closure, as both workers and members of the community are absent from the workplace as the sector moves online and becomes more closed.

<!-- ### Matrix $M^{\text{WW}}$: Worker-to-worker contacts -->

<!-- \begin{equation} -->
<!-- M_{j,j}^{\text{WW}}(x) = x_{j}(1-q_j)^2M_{j,j}^{\text{WW}}(\textbf{1}), -->
<!-- (\#eq:worker) -->
<!-- \end{equation} -->

<!-- for the working groups, with the number of contacts adjusted according to at-home working ($q_j$) and sector openness ($x_{j}$). As before, there is superlinear scaling of contacts with respect to working from home. There is linear scaling with respect to sector closure: that is, there are fewer contacts per person, but we do not approximate there being fewer people having them. This is because the latter is accounted for in the movement of people out of the group upon its closure.  -->

<!-- $$M_{j,j}^{\text{WW}}(x) = x_{j}^2(1-q_j)^2M_{j,j}^{\text{WW}}(\textbf{1})$$ -->

<!-- ```math -->
<!-- M^{\text{WW}}_{j,j}(x) = \hat{x}_j^2M^{\text{WW}}_{j,j}(\textbf{1}), \quad \hat{x}_j=\max(x_{j}-q_j,0) -->
<!-- ``` -->



## Uncosted transmission reductions

We parametrise the effects of 'uncosted transmission reductions' (UTR) in the model using Google's mobility data (Figure \@ref(fig:smoothmobility)). These changes in mobility were consequences of both government mandates and individual's choices. As we cannot separate the two, we consider a range of possibilities, based on the range of mobility changes observed for a given level of stringency (Figure \@ref(fig:mobilitydrop)). In our model, the mandated economic configuration leads to a change in contacts. We associate the reduction in contacts, which translates as a relative reduction in transmission, with the reduction in mobility. 


```{r smoothmobility,fig.cap='Mobility trajectories in 2020 for all countries, with points showing the point at which the largest drop was observed. Trajectories are averaged over "Retail and recreation", "Transit stations" and "Workplaces" and smoothed with a spline of 80 knots.', echo=F,message=F,warning=F, out.width="50%"}
knitr::include_graphics(path = "README_files/figure-gfm/smoothmobility.png")
```

```{r mobilitydrop,fig.cap='The largest drop in mobility plotted against the stringency on that date.', echo=F,message=F,warning=F, out.width="50%"}
knitr::include_graphics(path = "README_files/figure-gfm/mobilitydrop.png")
```

- We want to write mobility as a function of mandate and some epi outcome, e.g. deaths: $\rho(t) = (1-p^8)f(d(t),e(t)) + p^8$ where $\rho(t)$ is mobility, $d$ is deaths per million, $e$ is government mandate, and $`0 < p^8 < 1`$ is the baseline.
- We want mobility to drop monotonically with both the mandate and the epi outcome: $\frac{\partial f}{\partial d}<0$, $\frac{\partial f}{\partial e}<0$.
- We want a maximum mobility of 1 when both the mandate and the epi outcome are 0: $f(0,0)=1$.
- We want mobility to approach $p^8$ when the mandate and the epi outcome become large: $\lim_{d\to 10^6, e\to 1}f(d,e)= 0$.
- We want to allow for the possibility of redundancy between the two variables: $f(0,0)/f(0,e) > f(d,0)/f(d,e)$ and $f(0,0)/f(d,0) > f(0,e)/f(d,e)$ for $d,e>0$.

A simple model to achieve these criteria is: $$f(d,e) = \frac{1}{1+p^9d+p^{10}e}$$
with $p^9, p^{10}>0$.

<!-- However, we might also want a model that can be parametrised with a distribution whose uncertainty covers the whole range of possible eventualities. The equivalent model with compounded effects would be $$f_1(d,e) = \frac{1}{1+p^9 d}\frac{1}{1+p^{10}e}.$$ The equivalent model with completely overlapping effects would be $$f_2(d,e) = \frac{1}{1+\max(p^9 d,p^{10}e)}.$$ Then we could include 'model uncertainty' via some parameter $\beta\sim\mathcal{U}(0,1)$, defining $$f(d,e) = (f_1(d,e))^{p^{11}}(f_2(d,e))^{(1-p^{11})}.$$ -->

The implications of this modelling choice are that two extremes are possible in terms of behaviour under (unseen) circumstances of a severe moment in an outbreak: 1, it is possible that social distancing comes "free" (i.e. that you get the same reduction in transmission with and without closures and, without closures, there is no economic cost); and 2, there is no voluntary social distancing, and behaviour is independent of epidemiological circumstances. This is an assumption commonly made to create the counterfactual in evaluating impacts of vaccine programmes. This is a very large source of uncertainty, and we expect it to be identified as such in value-of-information analyses.

Finally, we assume that the effect wanes over time, with the minimum (baseline) tending to 1 with a rate of 0 to 0.1% per day.

```{r mobilityfitted,fig.cap='Fit of model to data.', echo=F,message=F,warning=F, out.width="50%"}
knitr::include_graphics(path = "README_files/figure-gfm/mobilityfitted.png")
```

```{r mobilityposterior,fig.cap='Posterior distribution for parameters $p^9$ and $p^8$.',  out.width="50%",echo=F,message=F,warning=F}
knitr::include_graphics(path = "README_files/figure-gfm/mobilityposterior.png")
```

```{r mobilitycurves,fig.cap='Sampled curves for four levels of mitigation. Data shown as points.', echo=F,message=F,warning=F, out.width="50%"}
knitr::include_graphics(path = "README_files/figure-gfm/mobilitycurves.png")
```


## Testing and self isolating

We assume that infectious people who know their status have a compliance $p^1\sim\text(Beta)(5,5)$ with the instruction to self isolate, starting one day into their infectious period. We assume constant infectiousness over time and that a fraction $p^{26}$ of the symptomatic infectiousness is presymptomatic. Then the amount of infectiousness averted of symptomatic people is $p^4=p^1(1-p^{26})$, who isolate due to the onset of symptoms. The fraction of asymptomatic cases identified by testing is $p^2(t)$. We assume asymptomatic cases have the same probability to self isolate and that test results are returned after $p^{17}$ days of infectiousness. Then the infectiousness that testing averts is $p^3(t)=p^1p^2(t)\min(0,(T^{I^a:R}-p^{17})/T^{I^a:R})$. 

<!-- b0    = 2.197; -->
<!-- b1    = 0.1838; -->
<!-- b2    = -1.024; -->
<!-- frac_cases_found = 1./(1+exp(b0+b1*Ip+b2*log10(trate))); -->
<!-- frac_cases_found(Ip >= trate) = min(frac_cases_found(Ip >= trate),trate/10^5); -->
<!-- frac_cases_found = max(frac_cases_found, trate/10^5 ); -->

# Econ model 

The economic model is measuring GDP by summing GVA over sectors and over time taking into account the extent to which sectors are open, as described in Section \@ref(lost-economic-activity). 

The economy is stratified by sector following the International Standard Industrial Classification of All Economic Activities (ISIC) Rev. 4 as used by the OECD [@un]. Economic output is measured as the sum of gross value added (GVA) of all sectors over the epidemic period, expressed as a percentage of pre-epidemic GVA summed over the same period. 

Openness comes primarily from the economic configuration which is a policy choice, mandated in response to the epidemic (see Section \@ref(closure-policies)). There are potentially additional losses due to worker sickness and death (see Section \@ref(lost-economic-activity)) and due to lost tourism, which is an exogenous random variable (see Section \@ref(impact-of-tourism)). We do not model changes to supply or demand, reductions in consumption and labour supply due to infection avoidance of individuals, interruptions in supply chains, or changes in imports and exports.

Lost education is also quantified monetarily and constitutes an economic cost. Unlike the other losses, they are not contemporaneous with the epidemic, but losses that unfold into the future. The assumptions and equations are described in Section \@ref(lost-education).

## Impact of tourism


### Food and accommodation services sector

As there is no "tourism" sector in the 45-sector classification we are using, to model the impact of changes to tourism, we identify the "Food and accommodation services" sector with tourism. This is imperfect. The correlation of their % contributions to GDP is 0.64 and the order of magnitude is similar (1 to 7% vs 2 to 10% of GDP). The other two sectors considered (Air transport and Arts, entertainment and recreation) have little correlation with tourism in terms of % of GDP. (See Figure \@ref(fig:pairs).)



```{r pairs, fig.cap="Correlations between tourism-related data. First: @untourismKeyTourismStatistics2023. Second to fourth: @untourismInternationalTourismCOVID192023. Fifth to seventh: OECD.",fig.height=7, fig.align="center",echo=F,warning=F,message=F}

data <- as.data.frame(readODS::read_ods('data/tourism.ods'))
# colnames(data) <- data[1,]
# data <- data[-1,]
for(j in 2:ncol(data)) data[,j] <- as.numeric(data[,j])


data$`International tourism as a share of GDP` <- data$`Tourism as a share of GDP (%)`/100 * data$`International tourism as share of total tourism (%)`

panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...) {
  usr <- par("usr")
  on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  keep <- !is.na(x) & !is.na(y)
  Cor <- abs(cor(x[keep], y[keep])) # Remove abs function if desired
  txt <- paste0(prefix, format(c(Cor, 0.123456789), digits = digits)[1])
  if(missing(cex.cor)) {
    cex.cor <- 0.4 / strwidth(txt)
  }
  text(0.5, 0.5, txt,
       cex = 1 + cex.cor * Cor) # Resize the text by level of correlation
}

my.text.panel <- function(labels) {
  function(x, y, lbl, ...) {
  spt <- strsplit(lbl,' ')[[1]]
    newtxt <- spt[1]
    for(j in 2:length(spt)){
      tst <- paste0(newtxt[length(newtxt)],' ',spt[j])
      if(nchar(tst)<15){
        newtxt[length(newtxt)] <- tst
      }else{
        newtxt[length(newtxt)+1] <- spt[j]
      }
    }
    text(x, y, paste0(newtxt,collapse='\n'), ...)
  }
}

pairs(data[,c(11,2:4,7:9)],
      text.panel = my.text.panel(c(Sepal.Length="Slen", Sepal.Width="Swid",
                                   Petal.Length="Plen", Petal.Width="Pwid")),
      upper.panel = panel.cor,    # Correlation panel
      lower.panel = panel.smooth)

```


\newpage


### Sector shrinkage as a result of the pandemic






For many countries, tourism was reduced in the COVID-19 pandemic not because of domestic mandates but because of reduced international travel. Therefore, the fraction of tourism that comes from abroad is a factor that can determine the impact of a pandemic on a country's GDP potentially independently of what happens within the country. (A useful model extension would be to include some dependence on country factors, e.g. case numbers.)

We model mitigation via business closures, which are mandated by sector. We represent openness with values $x$ which range from 0 to 1, 1 representing maximum openness. To capture the impact of reduced international travel, we set the maximum openness of the food and accommodation services sector to be limited by international tourism as:

```math
x = \min\{\hat{x}, 1+ b(c-1)\}
```

where $`\hat{x}`$ is the openness of the sector according to the schedule (i.e. the sector-closure policy), $b$ is the proportion of tourism that is international, and $c$ is the fraction international tourism reduces to as a consequence of the pandemic. I.e. the tourism remaining is the domestic ($1-b$) plus that that comes in from abroad ($bc$).

Therefore, the contribution of the GVA of the food and accommodation services sector is limited either by the pandemic, or by the sector-closure policy - whichever is lower.




```{r ,echo=F,warning=F,message=F}


ytd <- as.data.frame(readODS::read_ods('data/tourism.ods',sheet=2))

# colnames(ytd) <- ytd[1,]
# ytd <- ytd[-1,]
for(i in 2:ncol(ytd)) ytd[,i] <- as.numeric(ytd[,i])


meltytd <- melt(setDT(ytd),id.vars='Country')
meltdata <- reshape2::melt(data[,c(1:5)],id.vars='Country')
tourismhist <- ggplot() + 
  geom_histogram(data=meltytd,aes(x=value),colour='navyblue',fill='navyblue',bins=30) + 
  geom_histogram(data=meltdata,aes(x=value),colour='white',fill='grey',bins=30) + 
  facet_wrap(~variable,scales='free') +
  theme_bw(base_size = 15) + labs(x='',y='')



library(MASS)
dat <- ytd$`International tourist arrivals, YTD change (%)`/100 + 1
dat <- dat[!is.na(dat)]
fit_params <- fitdistr(dat,"lognormal")

# generate values given our fit parameters
x <- seq(0,max(dat),length=10000)
# hst <- hist(dat, breaks=x)
fit <- dlnorm(x, fit_params$estimate['meanlog'], fit_params$estimate['sdlog'])
```



### Loss of international tourists

We model the distribution of $c$ using data from 2020 (Figure \@ref(fig:tourismhist), bottom-right plot). We fit to it a log-normal distribution, and find mean value `r round(fit_params$estimate['meanlog'],2)` and standard deviation `r round(fit_params$estimate['sdlog'],2)` (Figure \@ref(fig:ytd)). We use these values as inputs for all country models.


```{r tourismhist, fig.cap="Distributions of tourism-related data from @untourismInternationalTourismCOVID192023. In grey are the subset of countries for which we have GVA data by sector.",fig.height=6, fig.width=9, fig.align="center",echo=F,warning=F,message=F, out.width="50%"}
tourismhist
```


```{r ytd, fig.cap="Fit of log-normal distribution to loss-of-tourism data.",fig.height=3, fig.align="center",echo=F,warning=F,message=F,fig.width=4}

ggplot() + geom_histogram(aes(x=dat,y=..density..),colour='navyblue',fill='grey',bins=30) +
  geom_line(aes(x=x,y=fit),colour='navyblue',size=2) +
  theme_bw(base_size=15) +
  scale_x_continuous(expand=c(0,0)) + 
  labs(x='Remaining international tourism',y='Density')

# plot the fit and original distributions
# plot(x, fit, type="l", ylab="Density",
#      xlab="X", ylim=c(0,max(hst$density)), xlim=c(0,2))
# title(main = "Density histogram with lognormal fit")
# lines(hst$mid, hst$density, type="l", col="red")
# legend(8,0.15,legend=c("Fit","Data"),lty=c(1,1),col=c("black","red"))
```



\newpage


### Dependence on international tourism

We model $b$ as a function of the share of GDP that comes from the sector. Note that the data we have for this are biased towards high-income countries.

We write 

$$b\sim\text{Beta}(\alpha(z),\beta(z))$$

where $z$ is the fraction of GDP coming from the Food and accommodation sector. We learn three parameters $p^5$, $p^6$ and $p^7$ to best fit the relationship between $z$ and $b$ in countries we have observations for:

$$p^5 = \alpha(z)+\beta(z)$$

$$p^6 z + p^7 = \frac{\alpha(z)}{\alpha(z)+\beta(z)}$$



```{r paramdist0,echo=F,warning=F,message=F}

paramdist <- read.csv('data/parameter_distributions.csv')
p5 <- paramdist$Parameter.1[paramdist$parameter_name=='tourism_pointiness']
p6 <- paramdist$Parameter.1[paramdist$parameter_name=='sec_to_international']
p7 <- paramdist$Parameter.2[paramdist$parameter_name=='sec_to_international']

formula1 <- sprintf(
  '$p^5=%s$',
  round(p5,2)
)
formula2 <- sprintf(
  '$p^6=%s$',
  round(p6,2)
)
formula3 <- sprintf(
  '$p^7=%s$',
  round(p7,2)
)


```




Here, $p^5$ controls the variance of the distribution and $p^6$ and $p^7$ the linear relationship between $z$ and $b$. Using an optimisation routine in R we find `r formula1`, 
`r formula2` and `r formula3`. Results are shown in Figure \@ref(fig:sectortourism). We use these values as inputs for all country models.

 ![(\#fig:sectortourism) Predicting the percentage of tourism that comes from abroad as a function of the size of the sector. Each row represents a beta distribution whose mean is determined by the size of the sector (z). Blue points show the data we have available (grey bars in Figure \@ref(fig:tourismhist)).](figures/sectortourism.png){ width=40% }

\newpage

## Remote working


For each sector in each country, we have the 90% interval for the proportion of people who can work from home from @Gottlieb2021. We assume that the value we sample within the range is related to internet infrastructure, so that a low value in one sector implies low values in all sectors. We:

- take the subset of countries in the income group (LLMIC / UMIC / HIC);
- take the minimum of the lower bounds by sector (5%);
- take the maximum of the upper bounds by sector (95%);
- sample from a uniform distribution between these bounds, taking the same quantile for each sector.

```{r internet,fig.cap='Internet access by income level. World Bank data for 2019.',echo=F,warning=F,message=F,include=F}
internetplot
```


We assume that remote working happens to its fullest extent for the whole period of mitigation for all policies.

<!-- We model the Figure \@ref(fig:internet) values with Beta distributions. For LLMICs, we have parameters `r round(llmic$estimate['shape1'],2)` and  `r round(llmic$estimate['shape2'],2)`. For UMICs, we have parameters `r round(mic$estimate['shape1'],2)` and  `r round(mic$estimate['shape2'],2)`. For HICs, we have parameters `r round(hic$estimate['shape1'],2)` and  `r round(hic$estimate['shape2'],2)`. -->

# Closure policies


Impacts of mandated closures of businesses and schools on epidemics can be described using three factors: length, stringency, and frequency. We model mandated closures using a discrete set of predefined policies, which specify the *stringency* of closures in each sector. The policies we use are the same for each country. The length and frequency of economic closures are endogenous to the model (via its epidemiology), and therefore depend on the dynamics of the epidemic that is being modelled. 

## Policy specifications

We define four generic policies that might be adopted once a novel pathogen has been identified. The policies represent possible choices that range from very stringent to laissez faire, and are grounded in real-life observations. We name the policies no closures (NC) and reactive closures 1 to 3 (RC1 to RC3), and they are depicted in Figure \@ref(fig:policies), structured by the qualities that distinguish them. 

The three sector-closure policies are each defined by a pair of economic configurations, and rules for moving between them. An economic configuration is a vector specifying the extent to which each sector is open, expressed as a percentage. Our economic configurations are constructed using data from three countries (Indonesia (RC1), the United Kingdom (RC2), and Australia (RC3)), via the manifest economic impacts in the wake of the COVID-19 pandemic. We take the sectoral GVA observed the COVID-19 pandemic expressed as a percentage of the values observed in the year before (OECD), i.e. we assume that the relative GVA reflects the degree to which sectors were open. 

In reality, the observed effects combined mandated closures, reductions in consumption and labour supply due to infection avoidance of individuals, interruptions in supply chains, and changes in  imports and exports. However, these effects have not been disentangled, and in DAEDALUS we model only the mandate. This is equivalent to saying that we assume the mandate alone determined economic outcomes and we simulate their repeated application. Thus we neglect two factors in our model: first, population behaviour, and second, international trade, and we ignore their impacts in the COVID-19 pandemic by subsuming all effects into the mandate. (e.g. a pandemic that does not originate in or impact greatly China might have a much smaller economic cost).

## Implementation

The economic configurations define the sector closures for both the economic model and the epidemiological model. Contacts associated with sectors -- between and among workers and customers -- are scaled down with closures. GVA per sector is scaled according to economic configurations in the economic model.

For their dynamic implementation in the model, the three closure policies follow the same general pattern: they are defined by two economic configurations, which we refer to as heavy and light (where the "heavy" configuration has higher stringency than the "light" configuration; the configurations are tabulated in Table \@ref(tab:eccon)). The light configuration is implemented at the response time. Thereafter, the level of closure for the three policies is mandated in response to the state of the epidemic, reverting between states as determined by the transmission dynamics. Tables \@ref(tab:rulesreactive) and \@ref(tab:ruleselimination) show the transitions and their conditions. RC1 and RC2 respond to hospital occupancy, allowing cases to rise and using closures to allow them to fall again. RC1 keeps schools closed throughout, whereas RC2 has schools open in the light configuration. RC3 aims to reduce cases and then to keep them low. All mitigation is suspended when the vaccine rollout has reached its target coverage (which is when 80% of the eligible population have been vaccinated). 



```{tikz policies, fig.cap = "The four sector-closure policy options. No closures (NC) does not mandate any closures. The other three policies all implement reactive closures (RC), either in response to hospital occupancy (RC1 and RC2) or $R_t$ (RC3). The difference between RC1 and RC2 is that in RC1 schools are closed throughout, whereas in RC2 schools are fully open during the light configuration.", fig.ext = 'png',echo=F,out.width="50%"}
\usetikzlibrary{shapes}
\usetikzlibrary{fit}
\usetikzlibrary{arrows}
\usetikzlibrary{positioning,arrows.meta}
\tikzset{
     block/.style={rectangle, draw, fill=red!40, text width=6em,
                   text centered, rounded corners, minimum height=3em},
     arrow/.style={-{Stealth[]}}
}
\tikzstyle{plate} = [draw, rectangle, rounded corners, fit=#1]
\tikzstyle{wrap} = [inner sep=0pt, fit=#1]
\tikzstyle{caption} = [font=\footnotesize, node distance=0] %
\tikzstyle{plate caption} = [caption, node distance=0, inner sep=0pt,
below left=5pt and 0pt of #1.south east] %
\tikzstyle{factor caption} = [caption] %
\tikzstyle{every label} += [caption] %

\newcommand{\plate}[4][]{ %
  \node[wrap=#3,#1] (#2-wrap) {}; % draw box round #3, called #2, with parameters #1
  \node[plate caption=#2-wrap] (#2-caption) {#4}; % fit caption
  \node[plate=(#2-wrap)(#2-caption)] (#2) {}; % draw (used to have #1)
}
\tikzset{box/.style={draw, diamond, thick, text centered, minimum height=0.5cm, minimum width=1cm}}
  \tikzset{line/.style={draw, thick, -latex'}}
\tikzstyle{latent} = [circle,fill=white,draw=black,inner sep=1pt,
minimum size=20pt, font=\fontsize{10}{10}\selectfont, node distance=1]
%\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1cm,y=1cm]
%\clip (-3, -10) rectangle (7, 1);
\begin{tikzpicture}[auto]
        \node [box, text width = 1.5cm,align=center]     (x3)      {Mandate closures?};
        \node [box, below=-0.5cm of x3, xshift=-3cm, text width = 1.5cm,align=center,color=blue]    (x1sx)    {NC};
        \node [box, below=-0.5cm of x3, xshift=3cm, text width = 1.5cm,align=center]     (x2dx)    {Responding to:};
        \node [box, below=-0.5cm of x2dx, xshift=-2cm, text width = 1.5cm,align=center]   (x1dx)    {Schools ever open?};
        \node [box, below=-0.5cm of x2dx, xshift=2cm, text width = 1.5cm,align=center,color=blue]    (A1dx)    {RC3};
        \node [box, below=-0.5cm of x1dx, xshift=-2cm, text width = 1.5cm,align=center,color=blue]  (A2dx)    {RC1};
        \node [box, below=-0.5cm of x1dx, xshift=2cm, text width = 1.5cm,align=center,color=blue]   (A3dx)    {RC2};
        %
        \path [line] (x3) -|   node[text width=1cm,align=center,above] {Yes}    (x2dx);
        \path [line] (x3) -|   node[text width=1cm,align=center,above] {No}     (x1sx);
        \path [line] (x2dx) -|   node[text width=1.75cm,align=center,above] {Hospital occupancy}       (x1dx);
        \path [line] (x2dx) -|    node[text width=1cm,align=center,above] {$R_t$}      (A1dx);
        \path [line] (x1dx) -|    node[text width=1cm,align=center,above] {No}   (A2dx);
        \path [line] (x1dx) -|    node[text width=1cm,align=center,above] {Yes}      (A3dx);
    \end{tikzpicture}

```


The sector-closure policies are defined as follows:

- NC: No closures are mandated. 
- RC1: Schools are mandated to close to 10% of pre-epidemic levels throughout, and other economic sectors close to the heavy-closure economic configuration when hospital occupancy reaches 95% of its capacity, and change to the light configuration once occupancy is less than 25% capacity.
- RC2: Sectors (including the education sector)  toggle between heavy and light closures reactively, as in RC1, albeit with slightly different economic configurations. 
- RC3: Heavy closures are chosen when $R_t>1.2$ and light closures when $R_t<0.95$. Closures are maintained until $R_t<1$ without closures, or vaccination targets are reached. 


All policies assume there is testing (Section \@ref(testing-and-self-isolating)), working from home (Section \@ref(remote-working)), and uncosted transmission reductions from behavioural changes (Section \@ref(uncosted-transmission-reductions)), which impact epidemiological outcomes. They do not directly impact economic outcomes, but indirectly may reduce the need for closures because of reduced incidence. 




| From/to | No closures | Light closures | Heavy closures |
|:----- |:----- |:----- |:----- |
| **No closures** |  | t $\geq$ response time AND Hospital occupancy > 95% capacity |  | 
| **Light closures** | (Growth rate < 0.025 OR Hospital occupancy < 25% capacity) AND vaccine rollout complete OR $R_t(M(\textbf{1})) < 1$ |  | Hospital occupancy > 95% capacity |
| **Heavy closures** |  | Hospital occupancy < 25% capacity AND t > 7 + last change time |  | 

Table: (\#tab:rulesreactive) State transition rules for policies RC1 and RC2. See Table \@ref(tab:eccon) for details of closures.

| From/to | No closures | Light closures | Heavy closures |
|:----- |:----- |:----- |:----- |
| **No closures** |  |  t $\geq$ response time OR Hospital occupancy > 95% capacity | | 
| **Light closures** | Vaccine rollout complete OR $R_t(M(\textbf{1})) < 1$  |  | $R_t > 1.2$ |
| **Heavy closures** | Vaccine rollout complete OR $R_t(M(\textbf{1})) < 1$  | $R_t(M(x_{\text{light closure}})) < 0.95$ AND t > 7 + last change time |  | 

Table: (\#tab:ruleselimination) State transition rules for policy RC3. See Table \@ref(tab:eccon) for details of closures.



```{r eccon,tab.cap='Economic configurations used to implement sector-closure policies. Values are the openness of the sector expressed as a percentage. RC3 values are taken from Australia; RC2 values are taken from the UK; RC1 values are taken from Indonesia, with data from OECD. Heavy closures are implemented in response to the epidemic. Thereafter, the level of closure is mandated in response to the state of the epidemic, reverting between states as necessary.',echo=F,warning=F,message=F}

eccon <- readxl::read_xlsx('data/6.economic_closures.xlsx',sheet='configurations')
for(j in 2:ncol(eccon)) eccon[,j] <- round(eccon[,j]*100)
colorder <- c(4,5,2,3,2,1)
eccon <- eccon[,c(0,colorder)+1]
colnames(eccon) <- c('Sector',rep(c('Heavy closures','Light closures'),times=3))

if (!knitr::is_html_output(excludes = "markdown")) { 
  pander(eccon,caption='Economic configurations used to implement strategies. Values are the openness of the sector expressed as a percentage. RC3 values are taken from Australia. Lockdown and RC2 values are taken from the UK. RC1 values are taken from Indonesia. \\label{tab:eccon}')
}else{
    x <- knitr::kable(eccon,escape=F, "html",caption='Economic configurations used to implement strategies. Values are the openness of the sector expressed as a percentage.  RC3 values are taken from Australia. Lockdown and RC2 values are taken from the UK. RC1 values are taken from Indonesia. \\label{tab:eccon}')
  kable_styling(x,full_width = F,latex_options = "HOLD_position") %>%
  add_header_above(c('',"RC1" = 2,"RC2" = 2,"RC3" = 2)) %>%
  kable_classic()
}

```



# Pathogen profiles

We sample pathogen profiles by defining distributions over the pathogen parameters. The distributions are made using sourced data (Table \@ref(tab:pathogenprofile)), and are described in Table \@ref(tab:pathogenparameters). Age profiles for severity rates are shown in Figure \@ref(fig:ratesbyage). We sample parameter values from distributions informed by the seven pathogen profiles. $\text{R}_0$ is truncated at 1.5 and 4 following @whittakerQuantifyingImpactBroadly2024. 



```{r pathogenprofile,tab.cap='',echo=F,warning=F,message=F}

pp <- readxl::read_xlsx('data/sevenpathogens.xlsx')
pp$`code label` <- NULL
nm <- colnames(pp)
pp <- data.frame(pp)
rownames(pp) <- pp$definition
colnames(pp) <- nm
pp$definition <- NULL
for(i in 1:ncol(pp)) pp[,i] <- format_to_print2(as.numeric(pp[,i]))
cp <- 'Pathogen profiles. IHR: infection hospitalisation rate. IFR: infection fatality rate. \\label{tab:pathogenprofile}'

if (!knitr::is_html_output(excludes = "markdown")) { 
  pander(pp,caption=cp)
}else{
    x <- knitr::kable(pp,escape=F, "html",caption=cp)
  kable_styling(x,full_width = F,latex_options = "HOLD_position") %>%
  kable_classic()
}

```


Model parameter name | Distribution | Distribution parameter values | Correlations 
|:----- |:----- |:----- |:----- |
Probability symptomatic | Beta | 14.68, 7.30 | None 
Latent period | Gamma | 2.28, 1.06 | None 
Asymptomatic infectious period | Gamma | 139.0, 0.017 | None 
Time from symptom onset to recovery | Gamma | 18.61, 0.17 | 0.99 (time to hospitalisation); 0.60 ($\text{R}_0$) 
Time from symptom onset to hospitalisation | Gamma | 21.21, 0.14 | 0.99 (time to recovery); 0.66 ($\text{R}_0$)
Time from hospitalisation to recovery | Gamma | 2.46, 3.75 | 0.997  
Time from hospitalisation to death | Gamma | 2.93, 2.96 | 0.997 
Time to immunity waning | Constant | Inf | None 
Relative infectiousness of asymptomatic | Constant | 0.58 | None 
$\text{R}_0$ | Truncated normal | 2.45, 1.32; (1.5, 4) | 0.60 (time to recovery); 0.66 (time to hospitalisation) 

Table: (\#tab:pathogenparameters) Distributions for pathogen parameters used to sample synthetic pathogens. Distributions are built from values in Table \@ref(tab:pathogenprofile).


![(\#fig:ratesbyage) Infection hospitalisation and fatality ratios are generated by modelling profiles from SARS and influenza ratios. x axis: age group index. y axis: log ratio. Colours: seven example profiles. Grey: sampled profiles. Profiles are built from values in Table \@ref(tab:pathogenprofile).](README_files/figure-gfm/ratesbyage.jpeg)



# DAEDALUS model parameters

In this section we list the parameters used to construct a country in order to run the model. We organise them by the way in which they are sampled. Fixed values are described elsewhere in the documentation.

## Sampling from empirical and uniform distributions

The following quantities are sampled from the set of values belonging to countries from one income level and/or uniform distributions:

- Population distribution by age
- Life expectancy
- Number of workers per sector
- GVA per worker per sector
- Community contact matrix
- Testing rate
- Scaling factors for all workplace-related contacts
- The extent to which there is uncosted transmission reduction
- Type of VSL calculation
- VSL elasticity
- Remote teaching effectiveness
- Date of importation
- Response time
- Size of epidemic seed


```{r ages,echo=F,warning=F,message=F}


hmaxi <- setDT(read.csv('data/country_data.csv'))

popcols <- which(grepl('Npop',colnames(hmaxi)))
hmaxi$meanage <- apply(hmaxi[,popcols,with=F],1,function(x)sum(x*c(1:length(x)))/sum(x))*5-2.5
hmaxi[,`Income group`:=igroup]
hmaxi[igroup%in%c('LIC','LMIC'),`Income group`:='LLMIC']
agedist <- hmaxi[,lapply(list(Mean=mean(meanage),Min=min(meanage),Max=max(meanage)),format_to_print2,3),by=`Income group`]

lg <- 'Mean ages for all countries within each income-level group. \\label{tab:agedist}'
if (!knitr::is_html_output(excludes = "markdown")) { 
  pander(agedist,caption=lg)
}else{
    x <- knitr::kable(agedist,escape=F, "html",caption=lg)
  kableExtra::kable_styling(x,full_width = F,latex_options = "HOLD_position")
}

```

```{r lifeexp,echo=F,warning=F,message=F}


lifeexpdist <- hmaxi[,lapply(list(Mean=mean(la1,na.rm=T),Min=min(la1,na.rm=T),Max=max(la1,na.rm=T)),format_to_print2,3),by=`Income group`]

lg <- 'Mean life expectancy for all countries within each income-level group. Life expectancy as given "Expected years of life remaining" for the youngest age group (0 to 4 years old). \\label{tab:agedist}'
if (!knitr::is_html_output(excludes = "markdown")) { 
  pander(lifeexpdist,caption=lg)
}else{
    x <- knitr::kable(lifeexpdist,escape=F, "html",caption=lg)
  kableExtra::kable_styling(x,full_width = F,latex_options = "HOLD_position")#%>%
  #footnote(general = 'Life expectancy as given "Expected years of life remaining" for the youngest age group (0 to 4 years old).', threeparttable = T, fixed_small_size = T)
}

```

## Sampling from parametric distributions informed by data

The following are sampled from parametric distributions:


```{r paramdist,tab.cap='Parameter distributions',echo=F,warning=F,message=F}

paramdist <- read.csv('data/parameter_distributions.csv')
colnames(paramdist) <- c('Parameter','Income group','Distribution','Parameter 1','Parameter 2')
paramdist <- subset(paramdist,Parameter!='bmi')
rownames(paramdist) <- NULL
paramdist$Parameter <- gsub('_',' ',paramdist$Parameter)
paramdist$Parameter <- gsub('pointiness','parameter sum',paramdist$Parameter)
paramdist$Parameter <- gsub('labsh','Labour share of GVA',paramdist$Parameter)
paramdist$Parameter <- gsub('Hmax','Hospital capacity',paramdist$Parameter)
paramdist$Parameter <- gsub('pt','Public transport frac',paramdist$Parameter)
paramdist$Parameter <- gsub('sec','Tourism',paramdist$Parameter)
paramdist$Parameter <- gsub('frac','fraction',paramdist$Parameter)
paramdist$Parameter <- gsub('schoolA1','Nursery contacts',paramdist$Parameter)
paramdist$Parameter <- gsub('schoolA2','School contacts',paramdist$Parameter)
paramdist$Distribution <- gsub('betainv','Beta',paramdist$Distribution)
paramdist$Distribution <- gsub('logninv','Log normal',paramdist$Distribution)
paramdist$Distribution <- gsub('gaminv','Gamma',paramdist$Distribution)
paramdist$`Parameter 1` <- round(paramdist$`Parameter 1`,2)
paramdist$`Parameter 2` <- round(paramdist$`Parameter 2`,2)

lg <- 'Parameter distributions. Tourism parameters are those described in Section \\@ref(dependence-on-international-tourism). "school1 fraction" and "school2 fraction" are the fractions of contacts that pre-school children and school-age children make in nursery and school, respectively. Work fraction is the fraction of contacts people in the working-age age group make in the workplace. hospitality1 fraction, hospitality2 fraction, hospitality3 fraction and hospitality4 fraction are the fractions of non-work, non-school contacts made in the hospitality setting for the four ordered age groups. hospitality age1, hospitality age2, hospitality age3 and hospitality age4 give the fractions of hospitality contacts made with age groups 20--64 and 65 and over, for the four age groups in order. Workforce in place is the fraction of 20 to 64 year olds counted among sector workers. (Workforce in place + unemployed = Workforce.)  Hospital capacity is beds per 100,000 population. \\label{tab:paramdist}'
if (!knitr::is_html_output(excludes = "markdown")) { 
  pander(paramdist,caption=lg)
}else{
    x <- knitr::kable(paramdist,escape=F, "html",caption=lg)
  kableExtra::kable_styling(x,full_width = F,latex_options = "HOLD_position")
}

```


### Hospital capacity

```{r hmax,fig.cap='Hospital capacity: available beds minus usual occupancy.',echo=F,warning=F,message=F, out.width="50%"}


ggplot(subset(hmaxi,!is.na(igroup)&igroup!='')) + 
  geom_histogram(aes(x=Hmax),colour='navyblue',fill='grey') +
  facet_wrap(~igroup) +
  theme_bw(base_size = 15) +
  labs(x='Hospital beds per 100,000',y='')


hic <- fitdistr(subset(hmaxi,!is.na(Hmax)&igroup=='HIC')$Hmax,"gamma")
mic <- fitdistr(subset(hmaxi,!is.na(Hmax)&igroup%in%c('UMIC'))$Hmax,"gamma")
llmic <- fitdistr(subset(hmaxi,!is.na(Hmax)&igroup%in%c('LMIC','LIC'))$Hmax,"gamma")

```

We model these values with gamma distributions. For LLMICs, we have parameters `r round(llmic$estimate['shape'],2)` and  `r round(llmic$estimate['rate'],2)`. For UMICs, we have parameters `r round(mic$estimate['shape'],2)` and  `r round(mic$estimate['rate'],2)`. For HICs, we have parameters `r round(hic$estimate['shape'],2)` and  `r round(hic$estimate['rate'],2)`. (Data sources: World Bank (beds); OECD, WHO euro (bed occupancy rates).)

### Labour share of GVA

We estimate the average annual income per working-age adult as the total GVA multiplied by the fraction of GVA that goes to labour divided by the number of working-age adults. For the fraction of GVA that goes to labour we use PWT estimates from 2011 (Figure \@ref(fig:labsh)). 

<!-- For the value of a year of education, we use results from [@Psacharopoulos2021a]. For an LIC, the cost of a lost school year is `r round(62*3/.9)`% of GDP. For a UMIC, the cost of a lost school year is `r round(22*3/.9)`% of GDP. For an HIC, the cost of a lost school year is `r round(9*3/.9)`% of GDP. -->

```{r labsh,fig.cap='Fraction of GVA that goes to labour (PWT, 2011).',echo=F,warning=F,message=F, out.width="50%"}


# L = PV Y alpha \gamma S beta

# L total loss
# PV present value of lost earning
# Y mean annual earnings
# alpha fraction of year
# \gamma rate of return for one year of school
# S number of students
# beta proportion affected

alpha <- 1/3
gamma <- .08
Y <- c(4377, 10470, 32687)
S <- c(141, 1117, 258)*1e6
beta <- .9
dr <- .03
PV <- (1-(1+dr)^(-45))/dr
gdp <- c(.588,31,54)*1e12
# PV*Y*alpha*gamma*S*beta/gdp*100

labs <- setDT(read_dta('data/lab_share_data.dta'))
labs[!is.na(labsh),maxyear:=max(year),by=countrycode]
labincome <- left_join(subset(labs,year==maxyear),incomelevels,by=c('countrycode'="Country.Code"))
labincome <- labincome[,.(labsh,IncomeGroup)]
ggplot(subset(labincome,!is.na(IncomeGroup)&IncomeGroup!='')) + 
  geom_histogram(aes(x=labsh),colour='navyblue',fill='grey') +
  facet_wrap(~IncomeGroup) +
  theme_bw(base_size = 15) +
  labs(x='Labour share of GVA, %',y='')


hic <- fitdistr(subset(labincome,!is.na(labsh)&IncomeGroup=='High income')$labsh,"beta",start=list(shape1=1,shape2=1))
mic <- fitdistr(subset(labincome,!is.na(labsh)&IncomeGroup%in%c('Upper middle income'))$labsh,"beta",start=list(shape1=1,shape2=1))
llmic <- fitdistr(subset(labincome,!is.na(labsh)&IncomeGroup%in%c('Low income','Lower middle income'))$labsh,"beta",start=list(shape1=1,shape2=1))

```

We model these values with Beta distributions. For LLMICs, we have parameters `r round(llmic$estimate['shape1'],2)` and  `r round(llmic$estimate['shape2'],2)`. For UMICs, we have parameters `r round(mic$estimate['shape1'],2)` and  `r round(mic$estimate['shape2'],2)`. For HICs, we have parameters `r round(hic$estimate['shape1'],2)` and  `r round(hic$estimate['shape2'],2)`.

### Vaccine administration

```{r vaxrate,fig.cap='Vaccines administered per day, on average, in each country as a percent of population. Data source: fully vaccinated people from OWID (2022).',echo=F,warning=F,message=F, out.width="50%"}

hmaxi <- subset(hmaxi,!is.na(arate)&!is.na(igroup)&igroup!='')


ggplot(subset(hmaxi,!is.na(igroup)&igroup!='')) + 
  geom_histogram(aes(x=arate/10^5*100),colour='navyblue',fill='grey') +
  facet_wrap(~igroup) +
  theme_bw(base_size = 15) +
  labs(x='Second doses administered per day, % population',y='')


```

Figure \@ref(fig:vaxrate) shows histograms of COVID-19 vaccine administration rates by income level. Values are estimates of administration rates of complete schedules given. Administration rates are estimated as the best-fit slope observed in the pandemic period (Figure \@ref(fig:vaxratemx)). The administration slope ideally represents the highest rate possible: rates are often low to begin with, due to limited supply. They are often low at the end, due to depleted demand.


Using the method illustrated in Figure \@ref(fig:vaxratemx), we estimate how many countries per income group surpassed an average maximum rate of 0.5% of the population per day:  `r round(100*sum(hmaxi$igroup=='HIC'&hmaxi$arate/10^5>.005)/sum(hmaxi$igroup=='HIC'))`% of HICs,   `r round(100*sum(hmaxi$igroup=='UMIC'&hmaxi$arate/10^5>.005)/sum(hmaxi$igroup=='UMIC'))`% of UMICs,  and `r round(100*sum(hmaxi$igroup%in%c('LMIC','LIC')&hmaxi$arate/10^5>.005)/sum(hmaxi$igroup%in%c('LMIC','LIC')))`% of LLMICs.



```{r vaxratemx,fig.cap='Vaccine administration in Mexico. The blue line shows the average rate over the whole vaccination campaign. The yellow line shows the average rate when administration was rate limiting.',echo=F,warning=F,message=F, out.width="50%"}

knitr::include_graphics(path = "README_files/figure-gfm/vax_rate_MX.png")

```

In LMICs and LICs, there was arguably not a period of vaccine delivery in which the rate was limited by neither demand nor supply. Therefore we use an alternative source to validate our choices of administration rate in different scenarios. 

Figure \@ref(fig:vaxratewho) shows that in 40% of vaccination campaigns in LLMICs, the rate exceeded 0.2% of the population per day; in 28% of campaigns, the rate exceeded 0.4% of the population per day; and in 13% of campaigns, the rate exceeded 1% of the population per day. We use these rates of delivery for LLMIC synthetic countries.

```{r vaxratewho,fig.cap='Vaccine administration rates in LLMICs. Shown is the cumulative distribution of delivery rate, measured as the % of the population vaccinated per day. The data consist of 141 points, from 55 countries that are currently classified as LIC or LMIC, from the years 2000 to 2022, of programmes for measles, MR or MMR vaccines, lasting two weeks or more [@whoSummaryMeaslesRubellaSupplementary2022]. The types of programme include campaigns and outbreak response as well as catch up, follow up, speed up, and mop up.',echo=F,warning=F,message=F, out.width="80%"}

knitr::include_graphics(path = "README_files/figure-gfm/vaccinationrates.png")

```

### Compliance with the requirement to self isolate

We use a broad Beta distribution with parameters (5,5) to describe the compliance of the population with the requirement to isolate if symptomatic or positive. A YouGov survey [@jonessarahpImperialCollegeLondon2020] asked "If you were advised to do so by a healthcare professional or public health authority to what extent are you willing or not to self-isolate for 7 days?" The question was asked in 30 different countries (21 high income, five upper-middle income, four lower-middle income) and 63 different weeks of the COVID-19 pandemic to a total of 837,368 people.

The possible answers were 'Very unwilling', 'Somewhat unwilling', 'Neither willing nor unwilling', 'Not sure', 'Somewhat willing', 'Very willing'.  Excluding the answer 'Not sure', and weighting all other answers on a uniform scale of 0 to 1, the average compliance from all participants is 84%. The range across countries is 73% to 90%. The average value for the UK is 87%. In contrast, @Smith2021 found that duration-adjusted adherence to full self isolation was 42.5%. The average value for Australia was 88%. A survey undertaken in 2009 found that 55% of households complied with quarantine requirements (https://doi.org/10.1186/1471-2334-11-2).

\newpage

```{r tvradio,echo=F,warning=F,message=F,include=F}

tvradio <- readxl::read_xlsx('data/DHS_MICS_MIS_assets-for-remote-learning_nat_subnat-1.xlsx')
tvradio <- tvradio[,c(2,13,21,29,56)]

tvradio <- readODS::read_ods('data/educationlosses.ods',col_names=T,sheet=2)

ggplot(subset(tvradio,is.na(mobile)&!country%in%c('sweden','china','botswana'))) +
  geom_label(aes(x=internet,y=`loss per week`,label=country)) + 
  theme_bw(base_size = 15) + labs(x='Internet',y='Education loss per week')
ggplot(subset(tvradio,!is.na(radio))) +
  geom_label(aes(x=radio,y=`loss per week`,label=country)) + 
  theme_bw(base_size = 15) + labs(x='Radio',y='Education loss per week')
ggplot(subset(tvradio,!is.na(tv))) +
  geom_label(aes(x=tv,y=`loss per week`,label=country)) + 
  theme_bw(base_size = 15) + labs(x='Mobile',y='Education loss per week')
ggplot(subset(tvradio,!is.na(mobile))) +
  geom_label(aes(x=mobile,y=`loss per week`,label=country)) + 
  theme_bw(base_size = 15) + labs(x='TV',y='Education loss per week')

```


# Notation

In general in this notation, subscripts are indices, and superscripts are never indices but instead define new labels. In particular, note that numerical superscripts are attached to letters $k$ for rates and $p$ for parameters. Where a power is applied to one of these letters, the letter will be enclosed in parentheses for clarity.


```{r echo=F,warning=F,message=F}

caps <- readODS::read_ods('letter_lookup.ods',sheet = 1)
caps$Letter <- paste0('$',caps$Letter,'$')
lg <- 'Capital letters'
cat(pander(caps,caption=lg, missing = ""))

# options(knitr.kable.NA = '')
# x <- knitr::kable(caps,escape=F, "html",caption=lg)
# (kableExtra::kable_styling(x,full_width = F,latex_options = "HOLD_position"))



lowercase <- readODS::read_ods('letter_lookup.ods',sheet = 2)
lowercase$Letter <- paste0('$',lowercase$Letter,'$')
lg <- 'Lower-case letters'
cat(pander(lowercase,caption=lg, missing = ""))


greek <- readODS::read_ods('letter_lookup.ods',sheet = 3)
greek$Letter <- paste0('$',greek$Letter,'$')
lg <- 'Greek letters'
cat(pander(greek,caption=lg, missing = ""))

rates <- readODS::read_ods('letter_lookup.ods',sheet = 4)
rates$Letter <- paste0('$',rates$Letter,'$')
lg <- 'Rates'
cat(pander(rates,caption=lg, missing = ""))

params <- readODS::read_ods('letter_lookup.ods',sheet = 5)
params$Letter <- paste0('$',params$Letter,'$')
lg <- 'Parameters'
cat(pander(params,caption=lg, missing = ""))


```

\newpage

